{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform each image into tensor and normalized with mean and std\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "# Define the batch size used each time we go through the dataset\n",
    "batch_size = 32\n",
    "\n",
    "# Set the training loader\n",
    "train_loader = torch.utils.data.DataLoader(datasets.MNIST('data', train=True, download=True, transform=transform), batch_size=batch_size, shuffle=True)\n",
    "# Set the testing loader\n",
    "test_loader = torch.utils.data.DataLoader(datasets.MNIST('data', train=False, download=True, transform=transform), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Init weights\n",
    "# 784 because there is 784 pixels in each image\n",
    "# 10 because there is 10 possible outputs : 0,1,2,3,4,5,6,7,8,9\n",
    "# Each pixel is linked to 10 outputs where each link is a weight to optimize\\\n",
    "# <=> Each class is linked to 784 pixel where each link is a weight to optimize\n",
    "weights = torch.randn(784, 10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1957,  0.1059, -2.6005,  ..., -0.1492, -0.2478,  1.5750],\n",
      "        [-0.6154,  0.9678,  1.2196,  ...,  0.2622,  0.5008,  1.2018],\n",
      "        [ 0.0975,  2.5442,  1.7177,  ..., -0.5051, -0.2357,  0.9957],\n",
      "        ...,\n",
      "        [ 0.6430, -1.1711,  0.0845,  ..., -1.1723, -0.6465,  0.2327],\n",
      "        [ 0.2031, -0.7183, -1.0854,  ..., -1.2435, -0.1675, -0.8184],\n",
      "        [ 0.7743, -0.4214, -1.6019,  ..., -0.5324, -0.8781,  1.0453]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([32, 1, 28, 28]) torch.Size([32])\n",
      " Accuracy on test set 0.0\n"
     ]
    }
   ],
   "source": [
    "def test(weights, test_loader):\n",
    "    test_size = len(test_loader.dataset)\n",
    "    correct = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        #print(batch_idx, data.shape, target.shape)\n",
    "        data = data.view((-1, 28*28))\n",
    "        print(batch_idx, data.shape, target.shape)\n",
    "        break\n",
    "        \n",
    "        outputs = torch.matmul(data, weights)\n",
    "        softmax = F.softmax(outputs, dim=1)\n",
    "        pred = softmax.argmax(dim=1, keepdim=True)\n",
    "        n_correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "        correct += n_correct\n",
    "\n",
    "    acc = correct / test_size\n",
    "    print(\" Accuracy on test set\", acc)\n",
    "    return\n",
    "\n",
    "test(weights, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss shape: 5.2075066566467285 Accuracy on test set 0.6566\n",
      "Loss shape: 4.9901828765869146 Accuracy on test set 0.7519\n",
      "Loss shape: 2.3272001743316653 Accuracy on test set 0.7971\n",
      "Loss shape: 3.634950876235962356 Accuracy on test set 0.8146\n",
      "Loss shape: 1.7423789501190186 Accuracy on test set 0.8315\n",
      "Loss shape: 0.86527872085571297 Accuracy on test set 0.8334\n",
      "Loss shape: 2.30662274360656742 Accuracy on test set 0.8453\n",
      "Loss shape: 1.62078392505645754367 Accuracy on test set 0.8405\n",
      "Loss shape: 1.58841729164123545 Accuracy on test set 0.8542\n",
      "Loss shape: 2.7017452716827393 Accuracy on test set 0.8557\n",
      "Loss shape: 0.7773103117942816673 Accuracy on test set 0.8555\n",
      "Loss shape: 2.37719821929931642 Accuracy on test set 0.8632\n",
      "Loss shape: 2.845596790313720715 Accuracy on test set 0.8651\n",
      "Loss shape: 2.56883502006530766 Accuracy on test set 0.865\n",
      "Loss shape: 1.50922656059265144 Accuracy on test set 0.8662\n",
      "Loss shape: 2.2973132133483887705 Accuracy on test set 0.8666\n",
      "Loss shape: 1.247497558593752663 Accuracy on test set 0.8736\n",
      "Loss shape: 0.149799033999443056 Accuracy on test set 0.8701\n",
      "Loss shape: 2.85308337211608956"
     ]
    }
   ],
   "source": [
    "it = 0\n",
    "for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "    # Be sure to start the loop with zeros grad\n",
    "    if weights.grad is not None:\n",
    "        weights.grad.zero_()\n",
    "    \n",
    "    data = data.view((-1, 28*28))\n",
    "    #print(\"batch_idx: {}, data.shape: {}, target.shape: {}\".format(batch_idx, data.shape, targets.shape))\n",
    "    outputs = torch.matmul(data, weights)\n",
    "    #print(\"outputs.shape: {}\".format(outputs.shape))\n",
    "\n",
    "    log_softmax = F.log_softmax(outputs, dim=1)\n",
    "    #print(\"Log softmax: {}\".format(log_softmax.shape))\n",
    "\n",
    "    #print((-log_softmax[0][targets[0]] + -log_softmax[1][targets[1]] )  / 2 )\n",
    "    #print(-log_softmax[0][targets[0]], targets[0])\n",
    "    \n",
    "    loss = F.nll_loss(log_softmax, targets)\n",
    "    print(\"\\rLoss shape: {}\".format(loss), end=\"\")\n",
    "    \n",
    "    # Compute the gradients for each variables\n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        weights -= 0.1*weights.grad\n",
    "        \n",
    "    it += 1\n",
    "    if it % 100 == 0:\n",
    "        test(weights, test_loader)\n",
    "        \n",
    "    if it > 5000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "batch_idx, (data, target) = next(enumerate(test_loader))\n",
    "data = data.view((-1, 28*28))\n",
    "\n",
    "outputs = torch.matmul(data, weights)\n",
    "softmax = F.softmax(outputs, dim=1)\n",
    "pred = softmax.argmax(dim=1, keepdim=True)\n",
    "\n",
    "plt.imshow(data[0].view(28, 28), cmap=\"gray\")\n",
    "plt.title(\"Predicted class {}\".format(pred[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
