{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform each image into tensor and normalized with mean and std\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "# Define the batch size used each time we go through the dataset\n",
    "batch_size = 32\n",
    "\n",
    "# Set the training loader\n",
    "train_loader = torch.utils.data.DataLoader(datasets.MNIST('data', train=True, download=True, transform=transform), batch_size=batch_size, shuffle=True)\n",
    "# Set the testing loader\n",
    "test_loader = torch.utils.data.DataLoader(datasets.MNIST('data', train=False, download=True, transform=transform), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Init weights\n",
    "# 784 because there is 784 pixels in each image\n",
    "# 10 because there is 10 possible outputs : 0,1,2,3,4,5,6,7,8,9\n",
    "# Each pixel is linked to 10 outputs where each link is a weight to optimize\\\n",
    "# <=> Each class is linked to 784 pixel where each link is a weight to optimize\n",
    "weights = torch.randn(784, 10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1957,  0.1059, -2.6005,  ..., -0.1492, -0.2478,  1.5750],\n",
      "        [-0.6154,  0.9678,  1.2196,  ...,  0.2622,  0.5008,  1.2018],\n",
      "        [ 0.0975,  2.5442,  1.7177,  ..., -0.5051, -0.2357,  0.9957],\n",
      "        ...,\n",
      "        [ 0.6430, -1.1711,  0.0845,  ..., -1.1723, -0.6465,  0.2327],\n",
      "        [ 0.2031, -0.7183, -1.0854,  ..., -1.2435, -0.1675, -0.8184],\n",
      "        [ 0.7743, -0.4214, -1.6019,  ..., -0.5324, -0.8781,  1.0453]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([32, 784]) torch.Size([32])\n",
      " Accuracy on test set 0.0\n"
     ]
    }
   ],
   "source": [
    "def test(weights, test_loader):\n",
    "    test_size = len(test_loader.dataset)\n",
    "    correct = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        #print(batch_idx, data.shape, target.shape)\n",
    "        data = data.view((-1, 28*28))\n",
    "        print(batch_idx, data.shape, target.shape)\n",
    "        break\n",
    "        \n",
    "        outputs = torch.matmul(data, weights)\n",
    "        softmax = F.softmax(outputs, dim=1)\n",
    "        pred = softmax.argmax(dim=1, keepdim=True)\n",
    "        n_correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "        correct += n_correct\n",
    "\n",
    "    acc = correct / test_size\n",
    "    print(\" Accuracy on test set\", acc)\n",
    "    return\n",
    "\n",
    "test(weights, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-6.6375e+01, -4.5260e+01, -2.7913e+01, -8.5335e+00, -3.8389e+01,\n",
      "         -3.3684e+01, -6.4412e+00, -1.7930e-03, -4.0020e+01, -4.4889e+01],\n",
      "        [-6.5237e+01, -1.4378e+01, -6.9867e+01, -5.2577e+01, -2.8496e+01,\n",
      "         -5.8315e+01, -1.8165e+01, -2.9329e+00, -5.7324e+01, -5.4713e-02],\n",
      "        [-5.9689e+01, -6.5596e+01, -1.2930e-02, -4.5298e+01, -8.8599e+01,\n",
      "         -9.3255e+01, -4.3547e+00, -1.4343e+01, -6.5479e+01, -2.6502e+01],\n",
      "        [-7.1841e+01, -3.2556e+01, -3.9537e+01, -6.1211e+01, -1.1294e+00,\n",
      "         -1.1261e+02, -3.9043e-01, -5.0897e+01, -2.9107e+01, -7.2305e+01],\n",
      "        [-6.9943e+01, -2.8169e+01, -2.4630e+01, -5.4376e+01, -2.4221e+01,\n",
      "         -7.4867e+01, -3.5545e-03, -5.6836e+01, -9.2504e+01, -5.6413e+00],\n",
      "        [-3.7770e+01, -2.2411e+01, -5.0251e+01, -9.7454e+00, -2.5935e+01,\n",
      "         -1.5516e-03, -2.9971e+01, -6.5077e+00, -2.7266e+01, -1.8542e+01],\n",
      "        [-2.7608e+01, -2.7974e+01, -2.3263e+00, -5.7176e+01, -3.8812e-01,\n",
      "         -4.3455e+01, -1.4983e+00, -1.6367e+01, -7.5161e+01, -7.6146e+00],\n",
      "        [-6.5798e+01,  0.0000e+00, -7.3978e+01, -3.0234e+01, -5.0968e+01,\n",
      "         -3.2657e+01, -3.3887e+01, -3.1675e+01, -7.0872e+01, -7.7051e+01],\n",
      "        [-2.4939e+01, -6.9104e+01, -8.4557e+01, -8.5818e+00, -2.9377e+01,\n",
      "         -6.8317e+01, -4.5154e+01, -3.1541e+01, -2.4577e+01, -1.8750e-04],\n",
      "        [-5.7957e+01, -5.6565e+01, -3.4828e+01, -1.9243e+01, -6.5812e+01,\n",
      "         -7.6432e+01, -4.8316e-04, -7.8485e+00, -3.3949e+01, -9.2860e+00],\n",
      "        [-6.3907e+01, -4.1271e+01, -3.0903e+01, -8.3641e+00, -3.5331e+01,\n",
      "         -5.7507e+01, -4.4359e+01, -2.3315e-04, -4.0727e+01, -4.9095e+01],\n",
      "        [-5.3081e+01, -4.0506e+01, -3.8001e+01,  0.0000e+00, -3.2629e+01,\n",
      "         -4.7731e+01, -2.7008e+01, -2.7111e+01, -4.4036e+01, -1.7550e+01],\n",
      "        [-4.9228e+01, -4.9180e+01, -6.2832e+01, -6.3562e+01, -4.8933e+01,\n",
      "         -8.4600e+01,  0.0000e+00, -6.2056e+01, -8.5594e+01, -6.5307e+01],\n",
      "        [-3.5441e+01, -2.4445e+01, -3.1857e+01, -3.3169e-03, -1.1299e+01,\n",
      "         -2.9481e+01, -5.7591e+00, -2.6766e+01, -8.8386e+00, -2.2563e+01],\n",
      "        [-4.9667e+01, -4.0691e+01, -4.3240e+01, -3.2740e+01, -4.0389e+01,\n",
      "         -5.9753e+01,  0.0000e+00, -3.4804e+01, -6.0459e+01, -3.7230e+01],\n",
      "        [-7.8372e+01, -5.3007e+01, -8.4397e-05, -7.6547e+01, -6.1384e+01,\n",
      "         -9.5173e+01, -9.3800e+00, -4.6842e+01, -9.8217e+01, -7.0311e+01],\n",
      "        [-5.3717e+01, -3.0093e+01, -1.6341e+01, -3.1894e+01, -3.8338e+00,\n",
      "         -4.5718e+01, -2.7568e-02, -5.1915e+00, -3.5377e+01, -1.8887e+01],\n",
      "        [-5.5704e+01, -1.2417e+01, -1.0610e+01, -1.0178e+01, -4.2376e+01,\n",
      "         -5.8525e+01, -1.4185e-04, -1.2662e+01, -2.1604e+01, -9.5407e+00],\n",
      "        [-6.5090e+01, -7.9997e+01, -1.2476e+01, -3.7516e+01, -8.6090e+01,\n",
      "         -9.4045e+01, -4.6957e+00, -9.1805e-03, -5.8221e+01, -4.7421e+01],\n",
      "        [-4.7653e+01, -6.6769e+01, -3.3688e+01, -4.5914e+01, -8.7951e+01,\n",
      "         -1.2410e+02,  0.0000e+00, -2.7521e+01, -6.0723e+01, -4.9120e+01],\n",
      "        [-6.5938e+01, -2.0414e+01, -5.2323e+01, -7.4347e-01, -4.8357e+01,\n",
      "         -3.9615e+01, -2.5858e+01, -2.2948e+01, -3.1502e+01, -6.4524e-01],\n",
      "        [-6.4936e+01, -4.8207e+01, -9.7814e+00, -6.8192e+01, -3.8423e+01,\n",
      "         -8.3248e+01, -2.1843e-03, -5.3439e+01, -8.1692e+01, -6.1538e+00],\n",
      "        [-9.4823e+01, -8.3573e+01, -5.4020e+01, -5.7387e+01, -8.7061e+01,\n",
      "         -8.9979e+01,  0.0000e+00, -4.0000e+01, -8.3031e+01, -1.1292e+02],\n",
      "        [-6.4993e+01,  0.0000e+00, -4.6664e+01, -6.0933e+01, -4.2409e+01,\n",
      "         -6.3210e+01, -3.3347e+01, -7.2125e+01, -6.1372e+01, -8.9333e+01],\n",
      "        [-9.2131e+01, -8.1193e+01, -9.3410e+00, -7.6710e+01, -5.1959e+01,\n",
      "         -1.2767e+02, -8.7734e-05, -5.6146e+01, -7.2600e+01, -9.2453e+01],\n",
      "        [-2.2692e+01, -2.3162e+01, -1.5155e+01, -5.4864e+01, -4.2326e+01,\n",
      "         -7.2256e+01, -7.0333e-06, -1.1923e+01, -5.9820e+01, -1.6497e+01],\n",
      "        [-6.4012e+01, -1.1613e+01, -1.7495e+01, -2.6348e+01, -2.4816e+00,\n",
      "         -4.8141e+01, -8.7324e-02, -4.7961e+01, -3.3918e+01, -3.3569e+01],\n",
      "        [-8.1502e+01, -6.2480e+01, -4.3354e+01, -4.9892e+01, -5.4241e+01,\n",
      "         -1.0036e+02,  0.0000e+00, -2.5065e+01, -6.1018e+01, -5.8616e+01],\n",
      "        [-4.3556e+01, -2.4261e+01, -1.5294e+01, -3.1986e+01, -1.7048e+01,\n",
      "         -6.3069e+01, -1.3015e+01, -5.2452e-06, -5.9340e+01, -1.2806e+01],\n",
      "        [-5.6192e+01, -6.2182e+01, -7.3836e+01, -5.1258e+01, -3.4681e+01,\n",
      "         -8.0649e+01,  0.0000e+00, -5.2589e+01, -3.4745e+01, -6.0388e+01],\n",
      "        [-7.1417e+01, -2.1422e+01, -6.7884e+01, -1.0034e+02, -7.8155e+01,\n",
      "         -5.3201e+01, -4.1916e+01, -8.6727e+01, -1.1213e+02,  0.0000e+00],\n",
      "        [-2.8472e+01, -3.5132e+01, -2.6656e+01, -2.3722e+01, -1.2524e+01,\n",
      "         -3.2119e+01, -5.6028e-06, -1.3142e+01, -2.1474e+01, -2.3635e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "it = 0\n",
    "for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "    # Be sure to start the loop with zeros grad\n",
    "    if weights.grad is not None:\n",
    "        weights.grad.zero_()\n",
    "    \n",
    "    data = data.view((-1, 28*28))\n",
    "    #print(\"batch_idx: {}, data.shape: {}, target.shape: {}\".format(batch_idx, data.shape, targets.shape))\n",
    "    outputs = torch.matmul(data, weights)\n",
    "    #print(\"outputs.shape: {}\".format(outputs.shape))\n",
    "\n",
    "    log_softmax = F.log_softmax(outputs, dim=1)\n",
    "    #print(\"Log softmax: {}\".format(log_softmax.shape))\n",
    "    print(log_softmax)\n",
    "    break\n",
    "    #print((-log_softmax[0][targets[0]] + -log_softmax[1][targets[1]] )  / 2 )\n",
    "    #print(-log_softmax[0][targets[0]], targets[0])\n",
    "    \n",
    "    loss = F.nll_loss(log_softmax, targets)\n",
    "    print(\"\\rLoss shape: {}\".format(loss), end=\"\")\n",
    "    \n",
    "    # Compute the gradients for each variables\n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        weights -= 0.1*weights.grad\n",
    "        \n",
    "    it += 1\n",
    "    if it % 100 == 0:\n",
    "        test(weights, test_loader)\n",
    "        \n",
    "    if it > 5000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "batch_idx, (data, target) = next(enumerate(test_loader))\n",
    "data = data.view((-1, 28*28))\n",
    "\n",
    "outputs = torch.matmul(data, weights)\n",
    "softmax = F.softmax(outputs, dim=1)\n",
    "pred = softmax.argmax(dim=1, keepdim=True)\n",
    "\n",
    "plt.imshow(data[0].view(28, 28), cmap=\"gray\")\n",
    "plt.title(\"Predicted class {}\".format(pred[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
