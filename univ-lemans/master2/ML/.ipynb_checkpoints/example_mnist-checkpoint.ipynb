{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform each image into tensor and normalized with mean and std\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "# Define the batch size used each time we go through the dataset\n",
    "batch_size = 32\n",
    "\n",
    "# Set the training loader\n",
    "train_loader = torch.utils.data.DataLoader(datasets.MNIST('data', train=True, download=True, transform=transform), batch_size=batch_size, shuffle=True)\n",
    "# Set the testing loader\n",
    "test_loader = torch.utils.data.DataLoader(datasets.MNIST('data', train=False, download=True, transform=transform), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Init weights\n",
    "# 784 because there is 784 pixels in each image\n",
    "# 10 because there is 10 possible outputs : 0,1,2,3,4,5,6,7,8,9\n",
    "# Each pixel is linked to 10 outputs where each link is a weight to optimize\\\n",
    "# <=> Each class is linked to 784 pixel where each link is a weight to optimize\n",
    "weights = torch.randn(784, 10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6691, -0.8548,  0.8228,  ..., -0.2059, -0.1670, -1.2352],\n",
      "        [ 1.5658, -0.3212,  0.9960,  ..., -0.2793, -0.7033,  1.1961],\n",
      "        [ 0.9765,  0.3999, -0.1186,  ...,  1.3988,  1.2356, -1.1661],\n",
      "        ...,\n",
      "        [-0.9946, -0.2594, -2.2248,  ...,  1.0299,  0.8551, -1.0055],\n",
      "        [ 1.1463, -1.1721, -0.0301,  ...,  0.2446, -0.3601,  0.9401],\n",
      "        [ 0.1329,  1.4909,  1.1913,  ..., -0.3442,  0.3680, -0.8185]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy on test set 0.1245\n"
     ]
    }
   ],
   "source": [
    "def test(weights, test_loader):\n",
    "    test_size = len(test_loader.dataset)\n",
    "    correct = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        #print(batch_idx, data.shape, target.shape)\n",
    "        data = data.view((-1, 28*28))\n",
    "        #print(batch_idx, data.shape, target.shape)\n",
    "\n",
    "        outputs = torch.matmul(data, weights)\n",
    "        softmax = F.softmax(outputs, dim=1)\n",
    "        pred = softmax.argmax(dim=1, keepdim=True)\n",
    "        n_correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "        correct += n_correct\n",
    "\n",
    "    acc = correct / test_size\n",
    "    print(\" Accuracy on test set\", acc)\n",
    "    return\n",
    "\n",
    "test(weights, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss shape: 0.8251365423202515___ 1\n",
      "Loss shape: 0.31856533885002136___ 2\n",
      "Loss shape: 0.026828717440366745___ 3\n",
      "Loss shape: 0.7669565081596375___ 4\n",
      "Loss shape: 0.24203860759735107___ 5\n",
      "Loss shape: 1.8464972972869873___ 6\n",
      "Loss shape: 0.5913946628570557___ 7\n",
      "Loss shape: 1.587731122970581___ 8\n",
      "Loss shape: 1.4747382402420044___ 9\n",
      "Loss shape: 1.1080982685089111___ 10\n",
      "Loss shape: 0.3445591926574707___ 11\n",
      "Loss shape: 1.4815845489501953___ 12\n",
      "Loss shape: 1.8771324157714844___ 13\n",
      "Loss shape: 1.2086398601531982___ 14\n",
      "Loss shape: 0.5412884950637817___ 15\n",
      "Loss shape: 0.9701464772224426___ 16\n",
      "Loss shape: 1.044447422027588___ 17\n",
      "Loss shape: 1.1798391342163086___ 18\n",
      "Loss shape: 2.7406809329986572___ 19\n",
      "Loss shape: 3.3063104152679443___ 20\n",
      "Loss shape: 1.447704553604126___ 21\n",
      "Loss shape: 1.371842861175537___ 22\n",
      "Loss shape: 0.34147557616233826___ 23\n",
      "Loss shape: 1.564876914024353___ 24\n",
      "Loss shape: 0.6932165026664734___ 25\n",
      "Loss shape: 0.6086694598197937___ 26\n",
      "Loss shape: 1.8412652015686035___ 27\n",
      "Loss shape: 1.433079719543457___ 28\n",
      "Loss shape: 2.7171802520751953___ 29\n",
      "Loss shape: 0.5247786045074463___ 30\n",
      "Loss shape: 0.6345379948616028___ 31\n",
      "Loss shape: 0.7139438390731812___ 32\n",
      "Loss shape: 0.6955651640892029___ 33\n",
      "Loss shape: 0.1540406197309494___ 34\n",
      "Loss shape: 0.17684228718280792___ 35\n",
      "Loss shape: 0.32334965467453003___ 36\n",
      "Loss shape: 3.0679779052734375___ 37\n",
      "Loss shape: 0.4779062867164612___ 38\n",
      "Loss shape: 0.1404310166835785___ 39\n",
      "Loss shape: 0.9761038422584534___ 40\n",
      "Loss shape: 0.8654190897941589___ 41\n",
      "Loss shape: 2.261823892593384___ 42\n",
      "Loss shape: 2.6729860305786133___ 43\n",
      "Loss shape: 1.7698445320129395___ 44\n",
      "Loss shape: 0.9325776100158691___ 45\n",
      "Loss shape: 0.34242644906044006___ 46\n",
      "Loss shape: 0.7453829050064087___ 47\n",
      "Loss shape: 1.5718908309936523___ 48\n",
      "Loss shape: 1.3048101663589478___ 49\n",
      "Loss shape: 0.5659617781639099___ 50\n",
      "Loss shape: 1.6095364093780518___ 51\n",
      "Loss shape: 1.821323037147522___ 52\n",
      "Loss shape: 2.045206308364868___ 53\n",
      "Loss shape: 1.601654291152954___ 54\n",
      "Loss shape: 1.7179409265518188___ 55\n",
      "Loss shape: 1.130981683731079___ 56\n",
      "Loss shape: 1.0927681922912598___ 57\n",
      "Loss shape: 2.8381309509277344___ 58\n",
      "Loss shape: 0.8931974768638611___ 59\n",
      "Loss shape: 0.4659135043621063___ 60\n",
      "Loss shape: 1.7194005250930786___ 61\n",
      "Loss shape: 0.14736388623714447___ 62\n",
      "Loss shape: 1.912832498550415___ 63\n",
      "Loss shape: 0.9819937348365784___ 64\n",
      "Loss shape: 0.723653256893158___ 65\n",
      "Loss shape: 1.5562196969985962___ 66\n",
      "Loss shape: 2.157217025756836___ 67\n",
      "Loss shape: 1.4288274049758911___ 68\n",
      "Loss shape: 1.1660600900650024___ 69\n",
      "Loss shape: 3.235276937484741___ 70\n",
      "Loss shape: 0.9179878234863281___ 71\n",
      "Loss shape: 2.666307210922241___ 72\n",
      "Loss shape: 0.7101466655731201___ 73\n",
      "Loss shape: 0.3864566683769226___ 74\n",
      "Loss shape: 1.6374484300613403___ 75\n",
      "Loss shape: 1.0993788242340088___ 76\n",
      "Loss shape: 0.13562928140163422___ 77\n",
      "Loss shape: 1.034597635269165___ 78\n",
      "Loss shape: 0.7046180963516235___ 79\n",
      "Loss shape: 2.759895086288452___ 80\n",
      "Loss shape: 1.021597981452942___ 81\n",
      "Loss shape: 3.1248867511749268___ 82\n",
      "Loss shape: 0.18398955464363098___ 83\n",
      "Loss shape: 2.170966148376465___ 84\n",
      "Loss shape: 2.1716017723083496___ 85\n",
      "Loss shape: 0.8316884636878967___ 86\n",
      "Loss shape: 0.8104769587516785___ 87\n",
      "Loss shape: 1.8583546876907349___ 88\n",
      "Loss shape: 0.2632962167263031___ 89\n",
      "Loss shape: 0.9844982624053955___ 90\n",
      "Loss shape: 1.5310091972351074___ 91\n",
      "Loss shape: 1.6241940259933472___ 92\n",
      "Loss shape: 0.25451865792274475___ 93\n",
      "Loss shape: 1.8957277536392212___ 94\n",
      "Loss shape: 1.1502960920333862___ 95\n",
      "Loss shape: 3.5685060024261475___ 96\n",
      "Loss shape: 0.3179662525653839___ 97\n",
      "Loss shape: 0.7360791563987732___ 98\n",
      "Loss shape: 1.71359121799469___ 99\n",
      "Loss shape: 0.15142586827278137 Accuracy on test set 0.8808\n",
      "___ 100\n",
      "Loss shape: 0.1840197592973709___ 101\n",
      "Loss shape: 1.6262245178222656___ 102\n",
      "Loss shape: 2.0313353538513184___ 103\n",
      "Loss shape: 1.548073172569275___ 104\n",
      "Loss shape: 0.5094163417816162___ 105\n",
      "Loss shape: 0.39287787675857544___ 106\n",
      "Loss shape: 2.025808811187744___ 107\n",
      "Loss shape: 1.2914416790008545___ 108\n",
      "Loss shape: 1.6609351634979248___ 109\n",
      "Loss shape: 1.6443548202514648___ 110\n",
      "Loss shape: 0.860703706741333___ 111\n",
      "Loss shape: 2.1720407009124756___ 112\n",
      "Loss shape: 0.41240936517715454___ 113\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e1f4bd580ccc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Be sure to start the loop with zeros grad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \"\"\"\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mnchannel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnchannel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m     \u001b[1;31m# put it from HWC to CHW format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# yikes, this transpose takes 80% of the loading time/CPU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "it = 0\n",
    "for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "    # Be sure to start the loop with zeros grad\n",
    "    if weights.grad is not None:\n",
    "        weights.grad.zero_()\n",
    "    \n",
    "    data = data.view((-1, 28*28))\n",
    "    #print(\"batch_idx: {}, data.shape: {}, target.shape: {}\".format(batch_idx, data.shape, targets.shape))\n",
    "    outputs = torch.matmul(data, weights)\n",
    "    #print(\"outputs.shape: {}\".format(outputs.shape))\n",
    "\n",
    "    log_softmax = F.log_softmax(outputs, dim=1)\n",
    "    #print(\"Log softmax: {}\".format(log_softmax.shape))\n",
    "\n",
    "    #print((-log_softmax[0][targets[0]] + -log_softmax[1][targets[1]] )  / 2 )\n",
    "    #print(-log_softmax[0][targets[0]], targets[0])\n",
    "    \n",
    "    loss = F.nll_loss(log_softmax, targets)\n",
    "    print(\"\\rLoss shape: {}\".format(loss), end=\"\")\n",
    "    \n",
    "    # Compute the gradients for each variables\n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        weights -= 0.1*weights.grad\n",
    "        \n",
    "    it += 1\n",
    "    if it % 100 == 0:\n",
    "        test(weights, test_loader)\n",
    "        \n",
    "    if it > 5000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "batch_idx, (data, target) = next(enumerate(test_loader))\n",
    "data = data.view((-1, 28*28))\n",
    "\n",
    "outputs = torch.matmul(data, weights)\n",
    "softmax = F.softmax(outputs, dim=1)\n",
    "pred = softmax.argmax(dim=1, keepdim=True)\n",
    "\n",
    "plt.imshow(data[0].view(28, 28), cmap=\"gray\")\n",
    "plt.title(\"Predicted class {}\".format(pred[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
