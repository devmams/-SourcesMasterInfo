{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green; font-family:Georgia; font-size:2.1m;\"> 1- Modèle de prediction 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green; font-family:Georgia; font-size:1.5m;\"> 1- Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mamdiallo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-11 19:37:35,062 - spacy_lefff.lefff - INFO - New LefffLemmatizer instantiated.\n",
      "2019-11-11 19:37:35,067 - spacy_lefff.lefff - INFO - Reading lefff data...\n",
      "2019-11-11 19:37:36,199 - spacy_lefff.lefff - INFO - Successfully loaded lefff lemmatizer\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from unidecode import unidecode\n",
    "import string\n",
    "from sklearn import svm\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopwords = stopwords.words('french')\n",
    "import spacy\n",
    "from spacy_lefff import LefffLemmatizer, POSTagger\n",
    "nlp = spacy.load('fr_core_news_sm')\n",
    "french_lemmatizer = LefffLemmatizer()\n",
    "nlp.add_pipe(french_lemmatizer, name='lefff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fichier = open(\"CorpusM2-AFD/corpus.tache1.learn\",\"r\",encoding = \"latin-1\")\n",
    "\n",
    "lignes = fichier.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for ligne in lignes:\n",
    "    ligne = ligne.replace('\\n','')\n",
    "    data.append(ligne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeroOuUn(c):\n",
    "    if c == 'C':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recupPersonne(s):\n",
    "    for i in range(0,len(s)):\n",
    "        if s[i]=='>':\n",
    "            return zeroOuUn(s[i-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def recupDonnees():\n",
    "#     X = []\n",
    "#     y = []\n",
    "#     for doc in data:\n",
    "#         doc1 = doc.split(' ')\n",
    "# #         doc1 =  [stemmer.stem(m) for m in doc1] #lemmetisation\n",
    "#     #     print(\" \".join(doc1[1:]))\n",
    "#         res = \" \".join(doc1[1:])        \n",
    "#         res = res.lower() #convertit les Majuscules en miniscules\n",
    "# #         print(res)\n",
    "#         doc_lem = nlp(res)\n",
    "#         phrase = \"\"\n",
    "#         for d in doc_lem:\n",
    "#             phrase += d.lemma_ +\" \"\n",
    "#         res = phrase\n",
    "#         res = res.split(' ')\n",
    "#         res = \" \".join([mot for mot in res if mot not in stopwords]) #suppression des stopwords\n",
    "#         res = unidecode(res) #suppression des accents et cedilles\n",
    "#         res = res.translate(str.maketrans('', '', string.punctuation)) #suprression des ponctuations\n",
    "        \n",
    "# #         print(res)\n",
    "#         X.append(res)\n",
    "#         y.append(recupPersonne(doc1[0]))\n",
    "# #         print(recupPersonne(doc1[0]))\n",
    "# #         break\n",
    "#     return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X,y = recupDonnees()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recupDonnees2():\n",
    "    X = []\n",
    "    y = []\n",
    "    f = open(\"data.txt\",\"r\")\n",
    "    lignes = f.readlines()\n",
    "    i = 0\n",
    "    for ligne in lignes:\n",
    "        i += 1\n",
    "        ligne = ligne.replace('\\n','')\n",
    "        doc = ligne.split(',')\n",
    "        X.append(\" \".join(doc[1:]))   \n",
    "        y.append(zeroOuUn(doc[0]))\n",
    "       \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = recupDonnees2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(y[:15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"J'épargnerai à mes lecteurs importante la liste complète de ces âpres négociations pour ne d'en sortir.\"\n",
    "# text = text.lower() #convertit les Majuscules en miniscules\n",
    "# doc_lem = nlp(text)\n",
    "# phrase = \"\"\n",
    "# for d in doc_lem:\n",
    "#     phrase += d.lemma_ +\" \"\n",
    "\n",
    "# text = phrase\n",
    "# text = text.split(' ')\n",
    "# text = \" \".join([mot for mot in text if mot not in stopwords]) #suppression des stopwords\n",
    "# text = unidecode(text) #suppression des accents et cedilles\n",
    "# text = text.translate(str.maketrans('', '', string.punctuation)) #suprression des ponctuations\n",
    "# print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# SEED = 987654321\n",
    "# random.seed(SEED)\n",
    "# random.shuffle(X)\n",
    "# random.shuffle(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  -  vouloir  ici  saluer ministre cooperation   nom   ancien president  lorsque etre depute  groupe france  gabon  temoigne interet qu avoir toujours porter gabon  plus  etre ami long date  \n"
     ]
    }
   ],
   "source": [
    "print(y[100], \" - \",X[39904])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  -  quand dire cher ami  agir la formule diplomatique  expression ressentir  \n",
      "1  -  avoir brazzaville  afrique demain dessine  \n",
      "0  -  etre vrai avoir tres souvent pays refus regarder droit devant soi  comme souhait rester la  certain peur changement  etre vrai  \n"
     ]
    }
   ],
   "source": [
    "print(y[0], \" - \",X[0])\n",
    "print(y[10], \" - \",X[10])\n",
    "print(y[12], \" - \",X[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57413, 143581)\n"
     ]
    }
   ],
   "source": [
    "mot_max = 10000\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,5),min_df=2)\n",
    "# vectorizer = TfidfVectorizer(max_features=mot_max,min_df=5, max_df=0.7)\n",
    "# vectorizer = TfidfVectorizer(min_df=5, max_df=0.7)\n",
    "# vectorizer = TfidfVectorizer(max_features=mot_max,ngram_range=(2,2),min_df=3, max_df=0.7)\n",
    "# vectorizer = TfidfVectorizer(max_features=mot_max, min_df=5, max_df=0.7)\n",
    "X_tfifd = vectorizer.fit_transform(X)\n",
    "print(X_tfifd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.309112265783739\n",
      "3.4353471442597003\n",
      "3.9990593249904043\n",
      "2.146956716267915\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(X_tfifd[0].toarray()))\n",
    "print(np.sum(X_tfifd[1].toarray()))\n",
    "\n",
    "print(np.sum(X_tfifd[15].toarray()))\n",
    "print(np.sum(X_tfifd[16].toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(vectorizer.get_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import TruncatedSVD\n",
    "# n = 1000\n",
    "# svd = TruncatedSVD(n_components=n)\n",
    "# X_tfifd = svd.fit(X_tfifd).transform(X_tfifd)\n",
    "# X_test = svd.fit(X_test).transform(X_test)\n",
    "# # X_train_svd = X_train\n",
    "# X_test_svd = X_test\n",
    "# print(xres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfifd, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45930, 143581)\n",
      "(11483, 143581)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Resultats ##################\n",
    "#(1,1) 1000 : 1324, 1322\n",
    "#(1,1) min(3) 1000 : 1314, 1308\n",
    "#(1,2) 1000 : 1328, 1308\n",
    "#(2,3) 1000 : 1447, 1434\n",
    "#(2,3) 1000 : 1476, 1477\n",
    "#(1,5) min(2) : 1168, 1071"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mamdiallo\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- %d (11483, 950)\n",
      "[[  355   808]\n",
      " [  142 10178]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.31      0.43      1163\n",
      "           1       0.93      0.99      0.96     10320\n",
      "\n",
      "    accuracy                           0.92     11483\n",
      "   macro avg       0.82      0.65      0.69     11483\n",
      "weighted avg       0.90      0.92      0.90     11483\n",
      "\n",
      "0.9172690063572237\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "clf_LOG = LogisticRegression(solver='lbfgs',multi_class='multinomial')\n",
    "clf_LOG.fit(X_train, y_train)\n",
    "y_pred_1 = clf_LOG.predict(X_test)\n",
    "y_pred_1_1 = clf_LOG.predict_proba(X_test)\n",
    "\n",
    "clf_LOG.score(X_test, y_test)\n",
    "print(\"---- %d\", (X_test.shape[0],(y_test != y_pred_1).sum()))\n",
    "print(confusion_matrix(y_test,y_pred_1))\n",
    "print(classification_report(y_test,y_pred_1))\n",
    "print(accuracy_score(y_test, y_pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "---------------------------------------------------------------------------\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 0 0 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1]\n",
      "[[0.03831372 0.96168628]\n",
      " [0.03807992 0.96192008]\n",
      " [0.03096559 0.96903441]\n",
      " [0.02818154 0.97181846]\n",
      " [0.07592823 0.92407177]\n",
      " [0.0318699  0.9681301 ]\n",
      " [0.06252911 0.93747089]\n",
      " [0.03689915 0.96310085]\n",
      " [0.0273682  0.9726318 ]\n",
      " [0.09576216 0.90423784]\n",
      " [0.00686154 0.99313846]\n",
      " [0.01062472 0.98937528]\n",
      " [0.03868264 0.96131736]\n",
      " [0.14677848 0.85322152]\n",
      " [0.04275166 0.95724834]\n",
      " [0.10855498 0.89144502]\n",
      " [0.01692318 0.98307682]\n",
      " [0.0489908  0.9510092 ]\n",
      " [0.18528049 0.81471951]\n",
      " [0.12654094 0.87345906]\n",
      " [0.03719728 0.96280272]\n",
      " [0.02414229 0.97585771]\n",
      " [0.37093068 0.62906932]\n",
      " [0.20170676 0.79829324]\n",
      " [0.34717136 0.65282864]\n",
      " [0.05436926 0.94563074]\n",
      " [0.1848281  0.8151719 ]\n",
      " [0.39882273 0.60117727]\n",
      " [0.11518127 0.88481873]\n",
      " [0.27968548 0.72031452]\n",
      " [0.09305948 0.90694052]\n",
      " [0.27948398 0.72051602]\n",
      " [0.73586357 0.26413643]\n",
      " [0.32091599 0.67908401]\n",
      " [0.04121117 0.95878883]\n",
      " [0.09191937 0.90808063]\n",
      " [0.05071755 0.94928245]\n",
      " [0.07825362 0.92174638]\n",
      " [0.11986308 0.88013692]\n",
      " [0.03288902 0.96711098]\n",
      " [0.35418336 0.64581664]\n",
      " [0.11475965 0.88524035]\n",
      " [0.22247715 0.77752285]\n",
      " [0.08544192 0.91455808]\n",
      " [0.14397129 0.85602871]\n",
      " [0.31181783 0.68818217]\n",
      " [0.4294147  0.5705853 ]\n",
      " [0.47751698 0.52248302]\n",
      " [0.01849683 0.98150317]\n",
      " [0.05782881 0.94217119]\n",
      " [0.18925994 0.81074006]\n",
      " [0.05018061 0.94981939]\n",
      " [0.13053335 0.86946665]\n",
      " [0.33163615 0.66836385]\n",
      " [0.09371356 0.90628644]\n",
      " [0.10368548 0.89631452]\n",
      " [0.10882335 0.89117665]\n",
      " [0.02499262 0.97500738]\n",
      " [0.35679583 0.64320417]\n",
      " [0.13237745 0.86762255]\n",
      " [0.24526751 0.75473249]\n",
      " [0.15081797 0.84918203]\n",
      " [0.02786642 0.97213358]\n",
      " [0.04555702 0.95444298]\n",
      " [0.04745093 0.95254907]\n",
      " [0.15328211 0.84671789]\n",
      " [0.0107841  0.9892159 ]\n",
      " [0.15451815 0.84548185]\n",
      " [0.04665856 0.95334144]\n",
      " [0.02388635 0.97611365]\n",
      " [0.04974615 0.95025385]\n",
      " [0.03525629 0.96474371]\n",
      " [0.03988727 0.96011273]\n",
      " [0.1827597  0.8172403 ]\n",
      " [0.04260108 0.95739892]\n",
      " [0.04988866 0.95011134]\n",
      " [0.05713611 0.94286389]\n",
      " [0.33963245 0.66036755]\n",
      " [0.18019958 0.81980042]\n",
      " [0.04794785 0.95205215]\n",
      " [0.40591537 0.59408463]\n",
      " [0.04115902 0.95884098]\n",
      " [0.09132633 0.90867367]\n",
      " [0.12446186 0.87553814]\n",
      " [0.03471612 0.96528388]\n",
      " [0.05488213 0.94511787]\n",
      " [0.05796016 0.94203984]\n",
      " [0.02356281 0.97643719]\n",
      " [0.04547676 0.95452324]\n",
      " [0.10662788 0.89337212]\n",
      " [0.06754404 0.93245596]\n",
      " [0.04613437 0.95386563]\n",
      " [0.08009902 0.91990098]\n",
      " [0.02364409 0.97635591]\n",
      " [0.01488538 0.98511462]\n",
      " [0.03846311 0.96153689]\n",
      " [0.0739655  0.9260345 ]\n",
      " [0.03006397 0.96993603]\n",
      " [0.0688955  0.9311045 ]\n",
      " [0.0470027  0.9529973 ]\n",
      " [0.16508744 0.83491256]\n",
      " [0.08616892 0.91383108]\n",
      " [0.04019508 0.95980492]\n",
      " [0.05940233 0.94059767]\n",
      " [0.05713642 0.94286358]\n",
      " [0.14347515 0.85652485]\n",
      " [0.02259864 0.97740136]\n",
      " [0.02419936 0.97580064]\n",
      " [0.13403074 0.86596926]\n",
      " [0.02737999 0.97262001]\n",
      " [0.07604248 0.92395752]\n",
      " [0.28174791 0.71825209]\n",
      " [0.07069342 0.92930658]\n",
      " [0.064949   0.935051  ]\n",
      " [0.02859271 0.97140729]\n",
      " [0.01345963 0.98654037]\n",
      " [0.25297473 0.74702527]\n",
      " [0.02894368 0.97105632]\n",
      " [0.05971959 0.94028041]\n",
      " [0.01804262 0.98195738]\n",
      " [0.02217939 0.97782061]\n",
      " [0.03673297 0.96326703]\n",
      " [0.04727867 0.95272133]\n",
      " [0.14906079 0.85093921]\n",
      " [0.22708795 0.77291205]\n",
      " [0.02543602 0.97456398]\n",
      " [0.0631975  0.9368025 ]\n",
      " [0.0285625  0.9714375 ]\n",
      " [0.1223614  0.8776386 ]\n",
      " [0.13803799 0.86196201]\n",
      " [0.05343903 0.94656097]\n",
      " [0.25065512 0.74934488]\n",
      " [0.0408454  0.9591546 ]\n",
      " [0.06305208 0.93694792]\n",
      " [0.34975878 0.65024122]\n",
      " [0.01393274 0.98606726]\n",
      " [0.05399465 0.94600535]\n",
      " [0.73451789 0.26548211]\n",
      " [0.43097365 0.56902635]\n",
      " [0.12077741 0.87922259]\n",
      " [0.20289012 0.79710988]\n",
      " [0.13548223 0.86451777]\n",
      " [0.37332617 0.62667383]\n",
      " [0.24994228 0.75005772]\n",
      " [0.15932577 0.84067423]\n",
      " [0.2720301  0.7279699 ]\n",
      " [0.23264459 0.76735541]\n",
      " [0.21406687 0.78593313]\n",
      " [0.75530595 0.24469405]\n",
      " [0.11412651 0.88587349]\n",
      " [0.7486957  0.2513043 ]\n",
      " [0.51366573 0.48633427]\n",
      " [0.18335024 0.81664976]\n",
      " [0.70346038 0.29653962]\n",
      " [0.26910918 0.73089082]\n",
      " [0.52144482 0.47855518]\n",
      " [0.03646881 0.96353119]\n",
      " [0.29433845 0.70566155]\n",
      " [0.2474161  0.7525839 ]\n",
      " [0.9301279  0.0698721 ]\n",
      " [0.51241575 0.48758425]\n",
      " [0.4677668  0.5322332 ]\n",
      " [0.10116359 0.89883641]\n",
      " [0.04893651 0.95106349]\n",
      " [0.08717085 0.91282915]\n",
      " [0.13886758 0.86113242]\n",
      " [0.05456164 0.94543836]\n",
      " [0.04083473 0.95916527]\n",
      " [0.01935495 0.98064505]\n",
      " [0.01153991 0.98846009]\n",
      " [0.00983666 0.99016334]\n",
      " [0.02429869 0.97570131]\n",
      " [0.01149447 0.98850553]\n",
      " [0.08547976 0.91452024]\n",
      " [0.05880998 0.94119002]\n",
      " [0.0322037  0.9677963 ]\n",
      " [0.06345976 0.93654024]\n",
      " [0.03781811 0.96218189]\n",
      " [0.01034696 0.98965304]\n",
      " [0.02776096 0.97223904]\n",
      " [0.05125591 0.94874409]\n",
      " [0.02772908 0.97227092]\n",
      " [0.04264398 0.95735602]\n",
      " [0.07772624 0.92227376]\n",
      " [0.08750102 0.91249898]\n",
      " [0.26745679 0.73254321]\n",
      " [0.03026487 0.96973513]\n",
      " [0.29703326 0.70296674]\n",
      " [0.09728627 0.90271373]\n",
      " [0.04331891 0.95668109]\n",
      " [0.04171176 0.95828824]\n",
      " [0.03053884 0.96946116]\n",
      " [0.10566416 0.89433584]\n",
      " [0.04264398 0.95735602]\n",
      " [0.17802132 0.82197868]\n",
      " [0.10473809 0.89526191]\n",
      " [0.12843992 0.87156008]\n",
      " [0.17256681 0.82743319]\n",
      " [0.13205164 0.86794836]\n",
      " [0.02766483 0.97233517]\n",
      " [0.0476977  0.9523023 ]\n",
      " [0.04589244 0.95410756]\n",
      " [0.04264398 0.95735602]\n",
      " [0.18578891 0.81421109]\n",
      " [0.03518568 0.96481432]\n",
      " [0.10784049 0.89215951]\n",
      " [0.09604974 0.90395026]\n",
      " [0.04745093 0.95254907]\n",
      " [0.04285311 0.95714689]\n",
      " [0.30734207 0.69265793]\n",
      " [0.01891086 0.98108914]\n",
      " [0.06493912 0.93506088]\n",
      " [0.06370527 0.93629473]\n",
      " [0.15140538 0.84859462]\n",
      " [0.06719537 0.93280463]\n",
      " [0.33018013 0.66981987]\n",
      " [0.06401036 0.93598964]\n",
      " [0.07614475 0.92385525]\n",
      " [0.03893801 0.96106199]\n",
      " [0.08732599 0.91267401]\n",
      " [0.08495111 0.91504889]\n",
      " [0.03301139 0.96698861]\n",
      " [0.01495136 0.98504864]\n",
      " [0.06669666 0.93330334]\n",
      " [0.06159961 0.93840039]\n",
      " [0.08326577 0.91673423]\n",
      " [0.24590804 0.75409196]\n",
      " [0.05310078 0.94689922]\n",
      " [0.13263658 0.86736342]\n",
      " [0.06542428 0.93457572]\n",
      " [0.11271996 0.88728004]\n",
      " [0.04493663 0.95506337]\n",
      " [0.05281    0.94719   ]\n",
      " [0.04011113 0.95988887]\n",
      " [0.06794331 0.93205669]\n",
      " [0.08648495 0.91351505]\n",
      " [0.14057652 0.85942348]\n",
      " [0.03299339 0.96700661]\n",
      " [0.21264743 0.78735257]\n",
      " [0.10891607 0.89108393]\n",
      " [0.08906525 0.91093475]\n",
      " [0.10810664 0.89189336]\n",
      " [0.02016218 0.97983782]\n",
      " [0.01777941 0.98222059]\n",
      " [0.10174753 0.89825247]\n",
      " [0.11427583 0.88572417]\n",
      " [0.09296656 0.90703344]\n",
      " [0.09678669 0.90321331]\n",
      " [0.08029928 0.91970072]\n",
      " [0.18126546 0.81873454]\n",
      " [0.03102847 0.96897153]\n",
      " [0.08109407 0.91890593]\n",
      " [0.03707589 0.96292411]\n",
      " [0.30251454 0.69748546]\n",
      " [0.12681586 0.87318414]\n",
      " [0.21097263 0.78902737]\n",
      " [0.08519023 0.91480977]\n",
      " [0.02871119 0.97128881]\n",
      " [0.16505364 0.83494636]\n",
      " [0.06201929 0.93798071]\n",
      " [0.14633603 0.85366397]\n",
      " [0.03363004 0.96636996]\n",
      " [0.21369309 0.78630691]\n",
      " [0.07220298 0.92779702]\n",
      " [0.08185105 0.91814895]\n",
      " [0.34856823 0.65143177]\n",
      " [0.18445552 0.81554448]\n",
      " [0.03263844 0.96736156]\n",
      " [0.19580233 0.80419767]\n",
      " [0.0779703  0.9220297 ]\n",
      " [0.02706639 0.97293361]\n",
      " [0.08272349 0.91727651]\n",
      " [0.35168588 0.64831412]\n",
      " [0.02843379 0.97156621]\n",
      " [0.02626575 0.97373425]\n",
      " [0.06356253 0.93643747]\n",
      " [0.04117459 0.95882541]\n",
      " [0.05451208 0.94548792]\n",
      " [0.02262973 0.97737027]\n",
      " [0.02952189 0.97047811]\n",
      " [0.03239878 0.96760122]\n",
      " [0.23609638 0.76390362]\n",
      " [0.03726364 0.96273636]\n",
      " [0.12848703 0.87151297]\n",
      " [0.23461066 0.76538934]\n",
      " [0.0293721  0.9706279 ]\n",
      " [0.09586546 0.90413454]\n",
      " [0.02810237 0.97189763]\n",
      " [0.04745093 0.95254907]\n",
      " [0.01913508 0.98086492]\n",
      " [0.02804815 0.97195185]\n",
      " [0.06474177 0.93525823]\n",
      " [0.10718142 0.89281858]\n",
      " [0.06493821 0.93506179]\n",
      " [0.21209796 0.78790204]\n",
      " [0.0589849  0.9410151 ]\n",
      " [0.08772623 0.91227377]\n",
      " [0.20958893 0.79041107]\n",
      " [0.08139604 0.91860396]\n",
      " [0.19308721 0.80691279]\n",
      " [0.04782765 0.95217235]\n",
      " [0.014545   0.985455  ]\n",
      " [0.09831172 0.90168828]\n",
      " [0.04931986 0.95068014]\n",
      " [0.00972669 0.99027331]\n",
      " [0.03173482 0.96826518]\n",
      " [0.03571875 0.96428125]\n",
      " [0.16703192 0.83296808]\n",
      " [0.37917838 0.62082162]\n",
      " [0.29743708 0.70256292]\n",
      " [0.12198183 0.87801817]\n",
      " [0.32107001 0.67892999]\n",
      " [0.32728653 0.67271347]\n",
      " [0.31399693 0.68600307]\n",
      " [0.36663639 0.63336361]\n",
      " [0.84132919 0.15867081]\n",
      " [0.77784664 0.22215336]\n",
      " [0.53249298 0.46750702]\n",
      " [0.88273742 0.11726258]\n",
      " [0.28089971 0.71910029]\n",
      " [0.97445636 0.02554364]\n",
      " [0.21933671 0.78066329]\n",
      " [0.91796512 0.08203488]\n",
      " [0.39061726 0.60938274]\n",
      " [0.70334324 0.29665676]\n",
      " [0.01581583 0.98418417]\n",
      " [0.03460067 0.96539933]\n",
      " [0.21609387 0.78390613]\n",
      " [0.07341571 0.92658429]\n",
      " [0.10098068 0.89901932]\n",
      " [0.02503922 0.97496078]\n",
      " [0.01453074 0.98546926]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [0.24135517 0.75864483]]\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(y_test[:814]))\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(y_pred_1[:814])\n",
    "print(y_pred_1_1[:814])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- %d (11483, 953)\n",
      "[[  484   679]\n",
      " [  274 10046]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.42      0.50      1163\n",
      "           1       0.94      0.97      0.95     10320\n",
      "\n",
      "    accuracy                           0.92     11483\n",
      "   macro avg       0.79      0.69      0.73     11483\n",
      "weighted avg       0.91      0.92      0.91     11483\n",
      "\n",
      "0.9170077505878255\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf_SVC = LinearSVC()\n",
    "\n",
    "clf_SVC.fit(X_train, y_train)\n",
    "\n",
    "y_pred_2 = clf_SVC.predict(X_test)\n",
    "\n",
    "clf_SVC.score(X_test, y_test)\n",
    "print(\"---- %d\", (X_test.shape[0],(y_test != y_pred_2).sum()))\n",
    "print(confusion_matrix(y_test,y_pred_2))\n",
    "print(classification_report(y_test,y_pred_2))\n",
    "print(accuracy_score(y_test, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1]\n",
      "---------------------------------------------------------------------------\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1\n",
      " 0 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 0 1 0 1 0 0 0 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_pred_2_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-1444b08dc7ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"---------------------------------------------------------------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m333\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred_2_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m333\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred_2_2' is not defined"
     ]
    }
   ],
   "source": [
    "print(np.asarray(y_test[:333]))\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(y_pred_2[:333])\n",
    "print(y_pred_2_2[:333])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# # classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "# classifier = RandomForestClassifier(n_estimators=10, random_state=0)\n",
    "# classifier.fit(X_train, y_train)\n",
    "# y_pred_3 = classifier.predict(X_test)\n",
    "# classifier.score(X_test, y_test)\n",
    "# print(\"---- %d\", (X_test.shape[0],(y_test != y_pred_3).sum()))\n",
    "# print(confusion_matrix(y_test,y_pred_3))\n",
    "# print(classification_report(y_test,y_pred_3))\n",
    "# print(accuracy_score(y_test, y_pred_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.asarray(y_test[:333]))\n",
    "# print(\"---------------------------------------------------------------------------\")\n",
    "# print(y_pred_3[:333])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.utils.data as utils\n",
    "# from torchvision import datasets, transforms\n",
    "# import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.set_default_tensor_type(torch.FloatTensor)\n",
    "# # print(torch.get_default_dtype())\n",
    "# transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# # train_data_tensor = torch.tensor(X_train_tfifd.toarray())\n",
    "# train_data_tensor = torch.tensor(X_train)\n",
    "# train_target_tensor = torch.tensor(np.asarray(y_train)) # transform to torch tensors\n",
    "\n",
    "# # test_data_tensor = torch.tensor(X_test_tfifd.toarray())\n",
    "# test_data_tensor = torch.tensor(X_test)\n",
    "# test_target_tensor = torch.tensor(np.asarray(y_test)) # transform to torch tensors\n",
    "\n",
    "# train_dataset = utils.TensorDataset(train_data_tensor,train_target_tensor) # create your datset\n",
    "# test_dataset = utils.TensorDataset(test_data_tensor,test_target_tensor) # create your datset\n",
    "\n",
    "# batch_size = 50\n",
    "# # Set the training loader\n",
    "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# # Set the testing loader\n",
    "# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights1 = torch.randn(n, 5, requires_grad=True)\n",
    "# weights2 = torch.randn(5, 2, requires_grad=True)\n",
    "\n",
    "# b1 = torch.randn((1, 5), requires_grad=True) # bias for hidden layer\n",
    "# b2 = torch.randn((1, 2), requires_grad=True) # bias for output layer\n",
    "\n",
    "# # b1 = torch.randn(500,)\n",
    "# # b2 = torch.randn((1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sigmoid_activation(z):\n",
    "#     return 1 / (1 + torch.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test(weights1, weights2,b1, b2, test_loader):\n",
    "#     test_size = len(test_loader.dataset)\n",
    "#     correct = 0\n",
    "\n",
    "#     for batch_idx, (data, target) in enumerate(test_loader):\n",
    "#         #print(batch_idx, data.shape, target.shape)\n",
    "# #         data = data.view((-1, 28*28))\n",
    "#         #print(batch_idx, data.shape, target.shape)\n",
    "#         data = data.float()\n",
    "#         target = target.to(dtype=torch.long)        \n",
    "#         z1 = torch.matmul(data, weights1) + b1\n",
    "#         a1 = sigmoid_activation(z1)\n",
    "        \n",
    "#         z2 = torch.matmul(a1, weights2) + b2\n",
    "        \n",
    "#         outputs = sigmoid_activation(z2)\n",
    "        \n",
    "#         softmax = F.softmax(outputs, dim=1)\n",
    "#         pred = softmax.argmax(dim=1, keepdim=True)\n",
    "#         n_correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "#         correct += n_correct\n",
    "\n",
    "#     acc = correct / test_size\n",
    "#     print(\" Accuracy on test set\", acc)\n",
    "#     return\n",
    "\n",
    "# test(weights1, weights2,b1, b2, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it = 0\n",
    "# for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "#     # Be sure to start the loop with zeros grad\n",
    "#     if weights1.grad is not None:\n",
    "#         weights1.grad.zero_()\n",
    "    \n",
    "#     if weights2.grad is not None:\n",
    "#         weights2.grad.zero_()\n",
    "        \n",
    "    \n",
    "#     if b1.grad is not None:\n",
    "#         b1.grad.zero_()\n",
    "        \n",
    "#     if b2.grad is not None:\n",
    "#         b2.grad.zero_()\n",
    "\n",
    "        \n",
    "        \n",
    "#     #print(\"batch_idx: {}, data.shape: {}, target.shape: {}\".format(batch_idx, data.shape, targets.shape))\n",
    "#     data = data.float()\n",
    "#     targets = targets.to(dtype=torch.long)\n",
    "#     z1 = torch.matmul(data, weights1) + b1\n",
    "#     a1 = sigmoid_activation(z1)\n",
    "        \n",
    "#     z2 = torch.matmul(a1, weights2) + b2\n",
    "    \n",
    "#     outputs = sigmoid_activation(z2)\n",
    "#     log_softmax = F.log_softmax(outputs, dim=1)\n",
    "#     #print(\"Log softmax: {}\".format(log_softmax.shape))\n",
    "\n",
    "#     #print((-log_softmax[0][targets[0]] + -log_softmax[1][targets[1]] )  / 2 )\n",
    "#     #print(-log_softmax[0][targets[0]], targets[0])\n",
    "    \n",
    "#     loss = F.nll_loss(log_softmax, targets)\n",
    "#     print(\"\\rLoss shape: {}\".format(loss), end=\"\")\n",
    "    \n",
    "#     # Compute the gradients for each variables\n",
    "#     loss.backward()\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         weights2 -= 0.1*weights2.grad\n",
    "#         weights1 -= 0.1*weights1.grad\n",
    "#         b2 -= 0.1*b2.grad\n",
    "#         b1 -= 0.1*b1.grad\n",
    "\n",
    "\n",
    "#     it += 1\n",
    "#     if it % 10 == 0:\n",
    "#         test(weights1, weights2,b1, b2, test_loader)\n",
    "        \n",
    "# #     if it > 50000:\n",
    "# #         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_idx, (data, target) = next(enumerate(test_loader))\n",
    "# data = data.float()\n",
    "# # for i in data[0]:\n",
    "# #     print(i)\n",
    "# print(target)\n",
    "# z1 = torch.matmul(data, weights1) + b1\n",
    "# a1 = sigmoid_activation(z1)       \n",
    "# z2 = torch.matmul(a1, weights2) + b2\n",
    "# outputs = sigmoid_activation(z2)\n",
    "# softmax = F.softmax(outputs, dim=1)\n",
    "# pred = softmax.argmax(dim=1, keepdim=True)\n",
    "# print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
