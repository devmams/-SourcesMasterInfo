{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green; font-family:Georgia; font-size:2.1m;\"> 1- Modèle de prediction 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green; font-family:Georgia; font-size:1.5m;\"> 1- Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mamdiallo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-17 18:40:51,904 - spacy_lefff.lefff - INFO - New LefffLemmatizer instantiated.\n",
      "2019-10-17 18:40:51,906 - spacy_lefff.lefff - INFO - Reading lefff data...\n",
      "2019-10-17 18:40:52,366 - spacy_lefff.lefff - INFO - Successfully loaded lefff lemmatizer\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from unidecode import unidecode\n",
    "import string\n",
    "from sklearn import svm\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopwords = stopwords.words('french')\n",
    "import spacy\n",
    "from spacy_lefff import LefffLemmatizer, POSTagger\n",
    "nlp = spacy.load('fr_core_news_sm')\n",
    "french_lemmatizer = LefffLemmatizer()\n",
    "nlp.add_pipe(french_lemmatizer, name='lefff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fichier = open(\"CorpusM2-AFD/corpus.tache1.learn\",\"r\",encoding = \"latin-1\")\n",
    "lignes = fichier.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for ligne in lignes:\n",
    "    ligne = ligne.replace('\\n','')\n",
    "    data.append(ligne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<100:1:C> Quand je dis chers amis, il ne s'agit pas là d'une formule diplomatique, mais de l'expression de ce que je ressens.\n",
      "dis\n",
      "dis\n",
      "diplomat\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import FrenchStemmer\n",
    "stemmer = FrenchStemmer()\n",
    "print(data[0])\n",
    "print(data[0].split(' ')[3])\n",
    "print(stemmer.stem(data[0].split(' ')[3]))\n",
    "print(stemmer.stem('diplomatique'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['au', 'aux', 'avec', 'ce', 'ces', 'dans', 'de', 'des', 'du', 'elle', 'en', 'et', 'eux', 'il', 'ils', 'je', 'la', 'le', 'les', 'leur', 'lui', 'ma', 'mais', 'me', 'même', 'mes', 'moi', 'mon', 'ne', 'nos', 'notre', 'nous', 'on', 'ou', 'par', 'pas', 'pour', 'qu', 'que', 'qui', 'sa', 'se', 'ses', 'son', 'sur', 'ta', 'te', 'tes', 'toi', 'ton', 'tu', 'un', 'une', 'vos', 'votre', 'vous', 'c', 'd', 'j', 'l', 'à', 'm', 'n', 's', 't', 'y', 'été', 'étée', 'étées', 'étés', 'étant', 'étante', 'étants', 'étantes', 'suis', 'es', 'est', 'sommes', 'êtes', 'sont', 'serai', 'seras', 'sera', 'serons', 'serez', 'seront', 'serais', 'serait', 'serions', 'seriez', 'seraient', 'étais', 'était', 'étions', 'étiez', 'étaient', 'fus', 'fut', 'fûmes', 'fûtes', 'furent', 'sois', 'soit', 'soyons', 'soyez', 'soient', 'fusse', 'fusses', 'fût', 'fussions', 'fussiez', 'fussent', 'ayant', 'ayante', 'ayantes', 'ayants', 'eu', 'eue', 'eues', 'eus', 'ai', 'as', 'avons', 'avez', 'ont', 'aurai', 'auras', 'aura', 'aurons', 'aurez', 'auront', 'aurais', 'aurait', 'aurions', 'auriez', 'auraient', 'avais', 'avait', 'avions', 'aviez', 'avaient', 'eut', 'eûmes', 'eûtes', 'eurent', 'aie', 'aies', 'ait', 'ayons', 'ayez', 'aient', 'eusse', 'eusses', 'eût', 'eussions', 'eussiez', 'eussent']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeroOuUn(c):\n",
    "    if c == 'C':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recupPersonne(s):\n",
    "    for i in range(0,len(s)):\n",
    "        if s[i]=='>':\n",
    "            return(zeroOuUn(s[i-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recupDonnees():\n",
    "    X = []\n",
    "    y = []\n",
    "    for doc in data:\n",
    "        doc1 = doc.split(' ')\n",
    "#         doc1 =  [stemmer.stem(m) for m in doc1] #lemmetisation\n",
    "    #     print(\" \".join(doc1[1:]))\n",
    "        res = \" \".join(doc1[1:])        \n",
    "        res = res.lower() #convertit les Majuscules en miniscules\n",
    "#         print(res)\n",
    "        doc_lem = nlp(res)\n",
    "        phrase = \"\"\n",
    "        for d in doc_lem:\n",
    "            phrase += d.lemma_ +\" \"\n",
    "        res = phrase\n",
    "        res = unidecode(res) #suppression des accents et cedilles\n",
    "        res = res.translate(str.maketrans('', '', string.punctuation)) #suprression des ponctuations\n",
    "        res = res.split(' ')\n",
    "        res = \" \".join([mot for mot in res if mot not in stopwords]) #suppression des stopwords\n",
    "#         print(res)\n",
    "        X.append(res)\n",
    "        y.append(recupPersonne(doc1[0]))\n",
    "#         break\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-02dd7c2439ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecupDonnees\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-3bacfc2a7fc3>\u001b[0m in \u001b[0;36mrecupDonnees\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#convertit les Majuscules en miniscules\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#         print(res)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mdoc_lem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mphrase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc_lem\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"__call__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE003\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE005\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.__call__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.predict\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.greedy_parse\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\thinc\\neural\\_classes\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[0mMust\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \"\"\"\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\thinc\\neural\\_classes\\model.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_parser_model.pyx\u001b[0m in \u001b[0;36mspacy.syntax._parser_model.ParserModel.begin_update\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_parser_model.pyx\u001b[0m in \u001b[0;36mspacy.syntax._parser_model.ParserStepModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\thinc\\neural\\_classes\\feed_forward.py\u001b[0m in \u001b[0;36mbegin_update\u001b[1;34m(self, X, drop)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\thinc\\api.py\u001b[0m in \u001b[0;36mbegin_update\u001b[1;34m(seqs_in, drop)\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseqs_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mseqs_in\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbp_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseqs_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbp_layer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\thinc\\neural\\_classes\\feed_forward.py\u001b[0m in \u001b[0;36mbegin_update\u001b[1;34m(self, X, drop)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\thinc\\neural\\_classes\\resnet.py\u001b[0m in \u001b[0;36mbegin_update\u001b[1;34m(self, X, drop)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbp_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\thinc\\neural\\_classes\\feed_forward.py\u001b[0m in \u001b[0;36mbegin_update\u001b[1;34m(self, X, drop)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\thinc\\neural\\_classes\\layernorm.py\u001b[0m in \u001b[0;36mbegin_update\u001b[1;34m(self, X, drop)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchild\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackprop_child\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[0mbackprop_child\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\thinc\\neural\\_classes\\maxout.py\u001b[0m in \u001b[0;36mbegin_update\u001b[1;34m(self, X__bi, drop)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdrop\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0mdrop\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_factor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0moutput__boc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgemm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX__bi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrans2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[0moutput__boc\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnO\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnP\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0moutput__boc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput__boc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput__boc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnO\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X, y = recupDonnees()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "SEED = 987654321\n",
    "random.seed(SEED)\n",
    "random.shuffle(X)\n",
    "random.shuffle(y)\n",
    "# print(X[0:10])\n",
    "# print(y[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y[0], \" - \",X[0])\n",
    "print(y[1], \" - \",X[1])\n",
    "print(y[12], \" - \",X[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mot_max = 1500\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# vectorizer = TfidfVectorizer(ngram_range=(4,4))\n",
    "vectorizer = TfidfVectorizer(max_features=1500,ngram_range=(3,3),min_df=3, max_df=0.7)\n",
    "# vectorizer = TfidfVectorizer(max_features=mot_max, min_df=5, max_df=0.7)\n",
    "\n",
    "X_tfifd = vectorizer.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8552674cc0e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfifd, y, test_size=0.2, random_state=0)\n",
    "mot_max = 2500\n",
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "\n",
    "print(len(X_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000', '10', '100', '11', '14', '15', '16', '1789', '20', '200', '22', '24', '25', '27', '30', '300', '320', '35', '40', '50', '60', '600', '700', '80', 'a380', 'abandon', 'abandonner', 'abord', 'aborde', 'aborder', 'aboutir', 'abri', 'absence', 'absolu', 'absolument', 'academie', 'acadien', 'acceder', 'acceleration', 'accelerer', 'accent', 'accentuer', 'acceptable', 'acceptation', 'accepte', 'accepter', 'acces', 'accessible', 'accident', 'accompagne', 'accompagnement', 'accompagner', 'accomplir', 'accomplissement', 'accord', 'accorde', 'accorder', 'accroissement', 'accroitre', 'accru', 'accueil', 'accueillir', 'accumuler', 'achat', 'achever', 'acquerir', 'acquis', 'acte', 'acteur', 'actif', 'action', 'actionnaire', 'activement', 'activite', 'actualite', 'actuel', 'actuellement', 'adaptation', 'adapte', 'adapter', 'adherer', 'adhesion', 'adjoint', 'admettre', 'administratif', 'administration', 'admirable', 'admiration', 'admire', 'admirer', 'adolescent', 'adopter', 'adoption', 'adosser', 'adresse', 'adresser', 'adulte', 'adversaire', 'aerien', 'aeronautique', 'aeroport', 'affaiblir', 'affaire', 'affecter', 'affection', 'affectueux', 'affinite', 'affirmation', 'affirme', 'affirmer', 'affrontement', 'affronter', 'afghanistan', 'afin', 'africain', 'afrique', 'age', 'agence', 'agent', 'agglomeration', 'aggraver', 'agir', 'agreable', 'agression', 'agricole', 'agriculteur', 'agriculture', 'aide', 'aider', 'ailleurs', 'aime', 'aimer', 'aimf', 'ainsi', 'air', 'airbus', 'aire', 'aiser', 'ajoute', 'ajouter', 'ajustement', 'al', 'alea', 'algerie', 'alignement', 'alimentaire', 'alleger', 'allemagne', 'allemand', 'aller', 'alliance', 'allie', 'allier', 'allocataire', 'allocation', 'allouer', 'alors', 'alsace', 'alternance', 'alternatif', 'alternative', 'ambassadeur', 'ambitieuser', 'ambitieux', 'ambition', 'ame', 'amelioration', 'ameliore', 'ameliorer', 'amenagement', 'amener', 'americain', 'amerindien', 'amerique', 'ami', 'amical', 'amicalement', 'amie', 'amitie', 'amitier', 'amour', 'amoureux', 'ampleur', 'amplifier', 'an', 'analyse', 'analyser', 'ancetre', 'ancien', 'ancrer', 'anglais', 'angoisse', 'angola', 'angolais', 'angouleme', 'animal', 'animer', 'annee', 'anniversaire', 'annoncer', 'annuel', 'anticiper', 'apaiser', 'apercevoir', 'apparaitre', 'appartenance', 'appartenir', 'appel', 'appele', 'appeler', 'application', 'applique', 'appliquer', 'apport', 'apporte', 'apporter', 'appreciation', 'apprecier', 'apprendre', 'apprentissage', 'appreter', 'approche', 'approfondir', 'approprie', 'approprier', 'appui', 'appuyer', 'apres', 'apresmidi', 'aquitaine', 'arabe', 'arbitrage', 'architecte', 'architecture', 'ardent', 'argent', 'argentin', 'argentine', 'arme', 'armee', 'armement', 'armenien', 'armer', 'arranger', 'arret', 'arreter', 'arriere', 'arrive', 'arrivee', 'arriver', 'art', 'article', 'artisan', 'artisanat', 'artisans', 'artiste', 'artistique', 'asiatique', 'asie', 'aspect', 'aspiration', 'aspirer', 'assainissement', 'assemblee', 'assez', 'assistanat', 'assistance', 'assister', 'associatif', 'association', 'associer', 'assume', 'assumer', 'assurance', 'assure', 'assurer', 'athene', 'athlete', 'atlantique', 'atout', 'atouts', 'attache', 'attachement', 'attacher', 'attaque', 'attaquer', 'atteindre', 'atteinte', 'attendre', 'attente', 'attentif', 'attention', 'attirer', 'attractif', 'attraction', 'attribution', 'aube', 'aucun', 'audace', 'audacieux', 'augmentation', 'augmenter', 'aujourd', 'aujourdhui', 'aupres', 'auquel', 'aussi', 'aussitot', 'autant', 'auteur', 'authentique', 'autochtone', 'automne', 'automobile', 'autonomie', 'autoriser', 'autorite', 'autour', 'autre', 'autrement', 'auxquel', 'auxquelle', 'auxquels', 'avai', 'avance', 'avancee', 'avancer', 'avant', 'avantage', 'avantposte', 'avenir', 'aventure', 'avion', 'avis', 'avocat', 'avoir', 'avril', 'axe', 'baisse', 'baisser', 'balistique', 'bangkok', 'banque', 'barbarie', 'barcelone', 'barriere', 'bas', 'base', 'bassin', 'bataille', 'batiment', 'batir', 'battre', 'beal', 'beau', 'beaucoup', 'beaute', 'bel', 'belle', 'benefice', 'beneficiaire', 'beneficier', 'benevole', 'berceau', 'berlin', 'besoin', 'beyrouth', 'bibliotheque', 'bicentenaire', 'bien', 'bienetre', 'bientot', 'bienvenue', 'bilan', 'bilateral', 'bioethique', 'biologique', 'blesse', 'blessure', 'blocage', 'boire', 'bolivie', 'bon', 'bonheur', 'bord', 'bordeaux', 'bosnie', 'bouger', 'bourse', 'bout', 'branche', 'bras', 'bravo', 'bref', 'bresil', 'bresilien', 'bretagne', 'breton', 'brillant', 'briser', 'britannique', 'brunei', 'bruxelle', 'budget', 'budgetaire', 'bureau', 'but', 'ca', 'cabinet', 'cadre', 'caisse', 'calai', 'calcul', 'caledonie', 'calendrier', 'camarade', 'cameroun', 'camp', 'campagne', 'canada', 'cancer', 'cancun', 'candidat', 'candidature', 'canne', 'canton', 'cap', 'capable', 'capacite', 'capital', 'capitale', 'car', 'caractere', 'caracterise', 'caraibe', 'carrefour', 'carriere', 'carte', 'cas', 'catastrophe', 'categorie', 'cause', 'causer', 'ceci', 'ceder', 'cela', 'celebre', 'celebrer', 'celle', 'celui', 'cent', 'centaine', 'centenaire', 'central', 'centre', 'cependant', 'cercle', 'ceremonie', 'certain', 'certaine', 'certainement', 'certains', 'certes', 'certitude', 'cesse', 'cesser', 'chacun', 'chaine', 'chair', 'chaleur', 'chaleureusement', 'chaleureux', 'chambre', 'champ', 'champion', 'chance', 'chancelier', 'change', 'changement', 'changer', 'chantier', 'chaque', 'charge', 'charger', 'charme', 'charte', 'chef', 'chemin', 'cher', 'cherche', 'chercher', 'chercheur', 'chez', 'chiffre', 'chimique', 'chine', 'chinois', 'choc', 'choisir', 'choix', 'chomage', 'chomeur', 'chose', 'chretien', 'ci', 'ciel', 'cinema', 'cinq', 'cinquante', 'cinquantieme', 'circonstance', 'circulation', 'cite', 'citer', 'citoyen', 'citoyennete', 'civil', 'civilisation', 'civique', 'civisme', 'clair', 'clairement', 'clarifier', 'classe', 'classique', 'cle', 'client', 'climat', 'climatique', 'club', 'code', 'coeur', 'coherence', 'coherent', 'cohesion', 'collaborateur', 'collaboration', 'collectif', 'collection', 'collectivement', 'collectivite', 'college', 'collegue', 'combat', 'combattant', 'combattre', 'combien', 'combler', 'comite', 'commandement', 'commander', 'comme', 'commence', 'commencer', 'comment', 'commerce', 'commercial', 'commission', 'commode', 'commun', 'communautaire', 'communaute', 'commune', 'communication', 'communiquer', 'compagnie', 'compagnon', 'comparable', 'comparaison', 'comparer', 'compatriote', 'compenser', 'competence', 'competent', 'competitif', 'competition', 'competitivite', 'complementaire', 'complementarite', 'complet', 'completer', 'complexe', 'comporte', 'comportement', 'comporter', 'composante', 'composer', 'comprehensible', 'comprehension', 'comprendre', 'compris', 'compromis', 'comptable', 'compte', 'compter', 'concentrer', 'conception', 'concerne', 'concerner', 'concert', 'concertation', 'concevoir', 'conciliation', 'concilier', 'concitoyen', 'conclure', 'conclusion', 'concourir', 'concours', 'concret', 'concurrence', 'concurrent', 'condamner', 'condition', 'conduire', 'conduite', 'conference', 'conferer', 'confiance', 'confiant', 'confier', 'confirme', 'confirmer', 'conflit', 'confondre', 'conforme', 'conformement', 'conforter', 'confrontation', 'confronte', 'confronter', 'congo', 'congres', 'conjoint', 'conjuguer', 'connaissance', 'connaissent', 'connaitre', 'conquerant', 'conquerir', 'conquete', 'consacrer', 'conscience', 'conscient', 'consecration', 'conseil', 'conseiller', 'consensus', 'consentir', 'consequence', 'consequent', 'conservateur', 'conserver', 'considerable', 'consideration', 'considerer', 'consiste', 'consolider', 'consommateur', 'consommation', 'constamment', 'constance', 'constant', 'constate', 'constater', 'constaton', 'conster', 'constitue', 'constituer', 'constitution', 'constitutionnel', 'construction', 'construire', 'consultatif', 'consulter', 'contact', 'contemporain', 'contemporaine', 'contentieux', 'contenu', 'conteste', 'contester', 'contexte', 'continent', 'contingent', 'continue', 'continuer', 'continuite', 'contour', 'contradiction', 'contradictoire', 'contrainte', 'contraire', 'contrat', 'contre', 'contrepartie', 'contribue', 'contribuer', 'contributeur', 'contribution', 'controle', 'controler', 'convaincre', 'convenir', 'convention', 'convergence', 'conversation', 'conviction', 'convier', 'cooperation', 'cooperer', 'coordination', 'coordonner', 'cordial', 'coree', 'coreen', 'corps', 'correspondre', 'correze', 'corriger', 'corruption', 'corse', 'cote', 'coter', 'couleur', 'coup', 'coupe', 'cour', 'courage', 'courageux', 'courant', 'courir', 'cours', 'course', 'court', 'cout', 'couteux', 'couvrir', 'craindre', 'crainte', 'creancier', 'createur', 'creation', 'creativite', 'credible', 'credit', 'creer', 'creuser', 'creuset', 'crime', 'crise', 'critere', 'critique', 'croi', 'croire', 'croiser', 'croissance', 'croissant', 'croitre', 'croix', 'croyance', 'croyez', 'cru', 'crucial', 'cruel', 'culte', 'cultiver', 'culture', 'culturel', 'culturelle', 'curieux', 'curiosite', 'cycle', 'cyclone', 'danger', 'dangereux', 'date', 'davantage', 'debat', 'debattre', 'deboucher', 'debut', 'decembre', 'decennie', 'decentralisation', 'decentraliser', 'dechet', 'dechirer', 'decide', 'decider', 'decideur', 'decisif', 'decision', 'declaration', 'declarer', 'declin', 'decourager', 'decouverte', 'decouvrir', 'decrire', 'defaut', 'defavorise', 'defendre', 'defense', 'defenseur', 'defensif', 'defi', 'deficit', 'definir', 'definition', 'definitivement', 'degager', 'degat', 'degradation', 'degre', 'dehors', 'deja', 'dejeuner', 'dela', 'delai', 'delegation', 'delegue', 'deleguer', 'delinquance', 'delinquant', 'delit', 'demain', 'demande', 'demander', 'demarche', 'demeur', 'demeurant', 'demeure', 'demeurent', 'demeurer', 'demi', 'demisiecle', 'democratie', 'democratique', 'demographique', 'demontre', 'demontrer', 'demunis', 'denoncer', 'dense', 'depart', 'departement', 'departemental', 'depassement', 'depasser', 'dependance', 'dependre', 'depense', 'depit', 'deplacement', 'deplacer', 'deploiement', 'deployer', 'depuis', 'depute', 'derive', 'dernier', 'derriere', 'desarmement', 'desenclavement', 'desequilibre', 'desert', 'desespoir', 'designer', 'desir', 'desirer', 'desireux', 'desordre', 'desormais', 'desquel', 'dessine', 'dessiner', 'dessus', 'destin', 'destination', 'destinee', 'destiner', 'destruction', 'detenir', 'determinant', 'determination', 'determiner', 'detourner', 'detresse', 'detriment', 'detruire', 'dette', 'deux', 'deuxieme', 'devant', 'developpe', 'developpement', 'developpemer', 'developper', 'developpes', 'devenir', 'devenue', 'deviennent', 'devient', 'devise', 'devoir', 'devouement', 'di', 'dialogue', 'dialoguer', 'dieu', 'difference', 'differend', 'different', 'differer', 'difficile', 'difficulte', 'diffusion', 'digne', 'dignite', 'dimension', 'diminuer', 'diminution', 'diplomatique', 'diplome', 'dire', 'direct', 'directement', 'directeur', 'direction', 'directive', 'dirigeant', 'diriger', 'dis', 'discipline', 'discours', 'discrimination', 'discussion', 'discuter', 'dison', 'disparaitre', 'disparition', 'disponibilite', 'disponible', 'dispose', 'disposer', 'dispositif', 'disposition', 'dissuasion', 'distance', 'distinction', 'distingue', 'distinguer', 'divergence', 'divers', 'diversification', 'diversifier', 'diversite', 'diviser', 'division', 'divorce', 'dix', 'dixhuit', 'dizaine', 'docteur', 'doctrine', 'doha', 'dollar', 'domaine', 'domicile', 'dominer', 'dommage', 'don', 'donc', 'donnant', 'donne', 'donnee', 'donner', 'donneur', 'dont', 'dorenavant', 'dos', 'dossier', 'dote', 'doter', 'douanier', 'double', 'douloureux', 'doute', 'douter', 'douze', 'dramatique', 'drame', 'dresser', 'drogue', 'droit', 'dumas', 'dur', 'durable', 'durablement', 'durant', 'duree', 'durement', 'durer', 'dynamique', 'dynamisme', 'eau', 'ecart', 'ecarter', 'echange', 'echanger', 'echeance', 'echeant', 'echec', 'echelle', 'echelon', 'echo', 'eclaire', 'eclairer', 'eclat', 'eclatant', 'ecole', 'ecologique', 'economie', 'economique', 'economiquement', 'ecouler', 'ecoute', 'ecouter', 'ecrire', 'ecrit', 'ecrivain', 'edifier', 'educatif', 'education', 'effacer', 'effectif', 'effectivement', 'effectuer', 'effet', 'efficace', 'efficacement', 'efficacite', 'efforcer', 'effort', 'egal', 'egalement', 'egalite', 'egard', 'egide', 'eglise', 'egoisme', 'egypte', 'eh', 'elaboration', 'elaborer', 'elan', 'elargie', 'elargir', 'elargissement', 'election', 'electrique', 'electronique', 'elegance', 'element', 'elementaire', 'eleve', 'elever', 'elire', 'eloigne', 'eloignement', 'eloigner', 'elu', 'elysee', 'emblee', 'emergence', 'emergent', 'emerger', 'eminent', 'emission', 'emotion', 'emouvant', 'empeche', 'empecher', 'empire', 'emploi', 'employer', 'emporter', 'empreinte', 'emprunter', 'encadrement', 'encadrer', 'enceinte', 'encore', 'encouragement', 'encourager', 'endetter', 'endeuiller', 'energie', 'enfance', 'enfant', 'enfermer', 'enfin', 'engage', 'engagement', 'engager', 'enjeu', 'enjeux', 'ennemi', 'enoncer', 'enracinement', 'enraciner', 'enregistrer', 'enrichir', 'enrichissement', 'enseignant', 'enseigne', 'enseignement', 'enseigner', 'ensembl', 'ensemble', 'ensuite', 'entamer', 'entendre', 'entente', 'enthousiasme', 'enthousiaste', 'entier', 'entourer', 'entraide', 'entrainement', 'entrainer', 'entraver', 'entre', 'entree', 'entreprenant', 'entreprendre', 'entrepreneur', 'entreprise', 'entrer', 'entretenir', 'entretien', 'envier', 'environ', 'environnement', 'environnemental', 'envisager', 'envoyer', 'epanouir', 'epanouissement', 'epargne', 'epargner', 'epidemie', 'epoque', 'epouse', 'epreuve', 'eprouve', 'eprouver', 'equilibre', 'equilibrer', 'equipe', 'equipement', 'equitable', 'equite', 'equivalent', 'eradiquer', 'ere', 'eriger', 'erreur', 'espace', 'espagne', 'espagnol', 'espece', 'esperance', 'espere', 'esperer', 'espoir', 'esprit', 'essai', 'essayer', 'essentiel', 'essentielle', 'essentiellement', 'essor', 'esthetique', 'estil', 'estime', 'estimer', 'etablir', 'etablissement', 'etape', 'etat', 'etatsuni', 'etatsunis', 'ete', 'etendre', 'etendue', 'ethique', 'ethnique', 'etonnant', 'etranger', 'etre', 'etroit', 'etroitement', 'etude', 'etudiant', 'etudier', 'euro', 'europe', 'europeen', 'evaluation', 'evenement', 'evian', 'evidemment', 'evidence', 'evident', 'eviter', 'evolue', 'evoluent', 'evoluer', 'evolution', 'evoque', 'evoquer', 'exactemer', 'examen', 'examiner', 'excellence', 'excellent', 'exception', 'exceptionnel', 'exceptionnelle', 'excessif', 'exclure', 'exclusion', 'excuser', 'executif', 'execution', 'exemplaire', 'exemple', 'exercer', 'exercice', 'exige', 'exigeant', 'exigence', 'exiger', 'exil', 'existant', 'existe', 'existence', 'existent', 'exister', 'expansion', 'experience', 'experimentation', 'experimenter', 'expert', 'expertise', 'explication', 'expliquer', 'exploitation', 'exploiter', 'explorer', 'exportateur', 'exportation', 'exporter', 'expose', 'exposer', 'exposition', 'expression', 'exprime', 'exprimer', 'extension', 'exterieur', 'extraordinaire', 'extreme', 'extremement', 'fabriquer', 'face', 'facette', 'facile', 'facilement', 'facilite', 'faciliter', 'facon', 'faconner', 'facteur', 'faculte', 'faible', 'faiblesse', 'faille', 'faim', 'faire', 'fait', 'falloir', 'familial', 'familier', 'famille', 'fatalite', 'faudrait', 'faute', 'faveur', 'favorable', 'favoriser', 'federal', 'federation', 'federer', 'felicitation', 'felicite', 'feliciter', 'femme', 'fer', 'ferme', 'fermer', 'festival', 'fete', 'feu', 'fevrier', 'fidele', 'fidelite', 'fier', 'fierte', 'figer', 'figure', 'fil', 'filiere', 'fille', 'fils', 'fin', 'finalement', 'finance', 'financement', 'financer', 'financier', 'financierement', 'finir', 'fiscal', 'fiscalite', 'fixe', 'fixer', 'fleau', 'fleuve', 'flotte', 'flux', 'fmi', 'foi', 'fois', 'fonction', 'fonctionnaire', 'fonctionnement', 'fond', 'fondamental', 'fondateur', 'fondation', 'fondement', 'fonder', 'fondre', 'fonds', 'football', 'force', 'forcer', 'foret', 'forger', 'formalite', 'formation', 'forme', 'former', 'formidable', 'formule', 'fort', 'forte', 'fortement', 'forter', 'forum', 'fosse', 'fou', 'fournir', 'foyer', 'fracture', 'fragile', 'franc', 'francais', 'france', 'franchir', 'francoallemand', 'francophone', 'francophonie', 'frappe', 'frapper', 'fraternel', 'fraternite', 'frere', 'froid', 'front', 'frontiere', 'fructueux', 'fruit', 'frustration', 'futur', 'g7', 'g8', 'gage', 'gagne', 'gagner', 'garant', 'garantie', 'garantir', 'garde', 'garder', 'gatt', 'gaulle', 'gaz', 'gendarmerie', 'gene', 'general', 'generalement', 'generation', 'genereux', 'generosite', 'genetique', 'geneve', 'genie', 'gens', 'geographie', 'geographique', 'gerer', 'geste', 'gestion', 'global', 'globe', 'glorieux', 'gout', 'gouvernance', 'gouvernement', 'gouvernemental', 'gouverner', 'gouverneur', 'grace', 'grand', 'grandebretagne', 'grandeur', 'grandir', 'gratitude', 'grave', 'gravite', 'groupe', 'groupement', 'guadeloupe', 'guadeloupeen', 'guatemala', 'guatemalteque', 'guere', 'guerir', 'guerison', 'guerre', 'guider', 'guimet', 'guyane', 'habitant', 'habitat', 'habitation', 'habiter', 'habitude', 'haine', 'handicap', 'handicape', 'handicaper', 'hanoi', 'harmonie', 'harmonieux', 'harmonisation', 'hasard', 'haut', 'haute', 'hauteur', 'helas', 'heritage', 'heriter', 'heritier', 'heros', 'heure', 'heureusement', 'heureux', 'heurter', 'hier', 'histoire', 'historique', 'hommage', 'homme', 'hongrie', 'hongrois', 'honneur', 'honorer', 'hopital', 'horizon', 'horreur', 'hors', 'hospitalier', 'hospitalite', 'hote', 'hotel', 'hui', 'huit', 'humain', 'humanisme', 'humaniste', 'humanitaire', 'humanite', 'humiliation', 'hypothese', 'ici', 'ideal', 'ideau', 'idee', 'identifier', 'identique', 'identite', 'ideologie', 'ider', 'ignorance', 'ignore', 'ignorer', 'ile', 'illustre', 'illustrer', 'image', 'imaginaire', 'imagination', 'imaginer', 'immediat', 'immediatement', 'immense', 'immigration', 'immobilisme', 'impact', 'imperatif', 'imperativement', 'imperieux', 'implantation', 'implanter', 'implication', 'implique', 'impliquer', 'importance', 'important', 'importe', 'impose', 'imposer', 'impossible', 'impot', 'impregner', 'impression', 'impressionnant', 'impressionner', 'impuissance', 'impulsion', 'impunite', 'inacceptable', 'inaugurer', 'incarne', 'incarner', 'incendie', 'incertitude', 'inciter', 'incomparable', 'incomprehension', 'incontournable', 'inde', 'independance', 'independant', 'indien', 'indifference', 'indiquer', 'indispensable', 'individu', 'individuel', 'industrialiser', 'industrie', 'industriel', 'inegalite', 'ineluctable', 'inevitable', 'infectieux', 'inflation', 'influence', 'information', 'informatique', 'informer', 'infrastructure', 'ingenieur', 'initial', 'initiative', 'injuste', 'injustice', 'innocent', 'innovant', 'innovation', 'innover', 'inoubliable', 'inquiet', 'inquietude', 'inscrire', 'insecurite', 'inserer', 'insertion', 'insister', 'inspire', 'inspirer', 'installation', 'installe', 'installer', 'instance', 'instant', 'instauration', 'instaurer', 'instituer', 'institut', 'institution', 'institutionnel', 'instrument', 'instrumer', 'insuffisant', 'integration', 'integre', 'integrer', 'intellectuel', 'intelligence', 'intense', 'intensifier', 'intensite', 'intention', 'interdiction', 'interdire', 'interessant', 'interesser', 'interet', 'intergouvernemental', 'interieur', 'interlocuteur', 'intermediaire', 'interministeriel', 'international', 'interne', 'internet', 'interrogation', 'interroger', 'intervenir', 'intervention', 'intimite', 'intolerance', 'introduire', 'inutile', 'inventer', 'invention', 'inverse', 'investir', 'investissement', 'investisseur', 'invitation', 'invite', 'inviter', 'irremplacable', 'irreversible', 'islam', 'islamique', 'isolement', 'israel', 'israelien', 'issu', 'italie', 'italien', 'ivoire', 'ivoirien', 'jamais', 'janvier', 'japon', 'japonais', 'jerusalem', 'jeter', 'jeu', 'jeune', 'jeunesse', 'johannesburg', 'joie', 'jordanie', 'joue', 'jouer', 'jour', 'journee', 'judiciaire', 'juge', 'jugement', 'juger', 'juif', 'juillet', 'juin', 'jumelage', 'juridiction', 'juridique', 'jurisprudence', 'juriste', 'jusque', 'juste', 'justement', 'justice', 'justifient', 'justifier', 'kananaskis', 'kilometre', 'kosovo', 'kyoto', 'laboratoire', 'laicite', 'laisse', 'laisser', 'laissez', 'lancement', 'lancer', 'langage', 'langue', 'large', 'largement', 'latin', 'laureat', 'lecon', 'lecture', 'legion', 'legislateur', 'legislatif', 'legislation', 'legitime', 'legitimement', 'legitimite', 'lendemain', 'lequel', 'lettre', 'leve', 'lever', 'liaison', 'liban', 'libanais', 'liberal', 'liberalisation', 'liberation', 'liberer', 'liberte', 'libre', 'librement', 'lien', 'lier', 'lieu', 'ligne', 'limite', 'limiter', 'linguistique', 'lire', 'lisbonne', 'liste', 'litterature', 'littoral', 'livre', 'livrer', 'local', 'logement', 'logique', 'loi', 'loin', 'lointain', 'londre', 'long', 'longtemps', 'lorrain', 'lors', 'lorsque', 'lourd', 'lourde', 'louvre', 'lucidite', 'lumiere', 'lusophone', 'lutte', 'lutter', 'luxembourg', 'lycee', 'lyon', 'maastricht', 'macedoine', 'madagascar', 'madame', 'madrid', 'maghreb', 'magistrat', 'magistrature', 'magnifique', 'mai', 'maillon', 'main', 'maint', 'maintenant', 'maintenir', 'maintien', 'maire', 'maison', 'maitre', 'maitrise', 'maitriser', 'majeste', 'majeur', 'majorite', 'mal', 'malade', 'maladie', 'malaise', 'malgre', 'malheur', 'mali', 'mandat', 'manger', 'maniere', 'manifestation', 'manifeste', 'manifester', 'manque', 'manquer', 'maquis', 'marchand', 'marche', 'maree', 'marge', 'marin', 'marine', 'maritime', 'maroc', 'marque', 'marquer', 'mars', 'marseille', 'martinique', 'massif', 'materiel', 'maternel', 'matiere', 'matin', 'mauritanie', 'mauvais', 'maximum', 'mayotte', 'mecanisme', 'meconnaitre', 'medaille', 'medecin', 'medecine', 'media', 'mediateur', 'mediation', 'medical', 'medicament', 'mediter', 'mediterranee', 'mediterraneen', 'meilleur', 'meler', 'membre', 'meme', 'memoire', 'menace', 'menacer', 'menager', 'mener', 'mentalite', 'mentionner', 'mepris', 'mer', 'merci', 'mercosul', 'mercosur', 'mere', 'merite', 'meriter', 'merveilleux', 'message', 'mesure', 'mesurer', 'methode', 'metier', 'metre', 'metro', 'metropol', 'metropole', 'metton', 'mettre', 'meurtrir', 'mexicain', 'mexique', 'microbe', 'midi', 'mien', 'mienne', 'mieux', 'milieu', 'militaire', 'militant', 'mille', 'millenaire', 'milliard', 'millier', 'million', 'minimum', 'ministere', 'ministeriel', 'ministre', 'minorite', 'miracle', 'mise', 'misere', 'mission', 'mobile', 'mobilisation', 'mobiliser', 'mobilite', 'modalite', 'mode', 'modele', 'moderne', 'modernisation', 'moderniser', 'modernite', 'modeste', 'modifier', 'moindre', 'moins', 'mois', 'moitie', 'moment', 'monde', 'mondial', 'mondialisation', 'monetaire', 'monnaie', 'monsieur', 'montant', 'montee', 'monterrey', 'montre', 'montrer', 'monument', 'moral', 'mort', 'mot', 'moteur', 'motif', 'mourir', 'mouvement', 'moyen', 'moyenne', 'moyenorient', 'multilateral', 'multiple', 'multiplier', 'multipolaire', 'municipal', 'mur', 'musee', 'muser', 'musique', 'musulman', 'mutation', 'mutualite', 'mutuel', 'mutuellement', 'naissance', 'naitre', 'nation', 'national', 'nationalite', 'nations', 'nature', 'naturel', 'naturellement', 'neanmoins', 'necessaire', 'necessairement', 'necessite', 'necessiter', 'negatif', 'negligeable', 'negliger', 'negociateur', 'negociation', 'negocier', 'nepad', 'neuf', 'new', 'ni', 'nice', 'niger', 'niveau', 'nobel', 'noblesse', 'noir', 'nom', 'nombre', 'nombreux', 'non', 'nord', 'normal', 'norme', 'notamment', 'noter', 'notion', 'notres', 'nouer', 'nourrir', 'nouveau', 'nouvelle', 'novateur', 'novembre', 'nucleaire', 'nuit', 'nul', 'nunavut', 'objectif', 'objet', 'obligation', 'obligatoire', 'obliger', 'observation', 'observe', 'observer', 'obstacle', 'obtenir', 'occasion', 'occident', 'occidental', 'occupe', 'occuper', 'ocean', 'octobre', 'oeil', 'oeuvre', 'oeuvrer', 'officiel', 'officier', 'offre', 'offrir', 'olympique', 'omc', 'onu', 'onze', 'operateur', 'operation', 'operationnel', 'opinion', 'oppose', 'opposer', 'opposition', 'or', 'ordonnance', 'ordre', 'ore', 'organisation', 'organise', 'organiser', 'organisme', 'orient', 'orientation', 'orienter', 'original', 'origine', 'orleans', 'ose', 'otan', 'oublier', 'ouest', 'oui', 'outil', 'outre', 'outremer', 'ouvert', 'ouverture', 'ouvrage', 'ouvrier', 'ouvrir', 'pacifique', 'pacte', 'page', 'pain', 'pair', 'paix', 'palais', 'palestinien', 'panache', 'parait', 'paraitre', 'parallelement', 'paralympique', 'parce', 'parcourir', 'parcours', 'parent', 'parental', 'parfaitement', 'parfois', 'pari', 'paris', 'parisien', 'parle', 'parlement', 'parlementaire', 'parler', 'parlion', 'parmi', 'parole', 'part', 'partage', 'partagent', 'partager', 'partenaire', 'partenariat', 'parti', 'participation', 'participe', 'participer', 'particularite', 'particulier', 'particulierement', 'partie', 'partir', 'partisan', 'partout', 'party', 'parvenir', 'passage', 'passe', 'passer', 'passion', 'passionner', 'patience', 'patient', 'patrie', 'patrimoine', 'pauvre', 'pauvrete', 'pavillon', 'payer', 'pays', 'paysage', 'paysan', 'peche', 'pedagogique', 'peine', 'penal', 'pendant', 'penetrer', 'pense', 'pensee', 'penser', 'percevoir', 'perdre', 'pere', 'performance', 'performant', 'peril', 'periode', 'permanence', 'permanent', 'permettez', 'permettra', 'permettre', 'perseverance', 'perseverer', 'personn', 'personnage', 'personnaliser', 'personnalite', 'personne', 'personnel', 'personnellement', 'perspectif', 'perspective', 'perte', 'peser', 'petit', 'peu', 'peuple', 'peur', 'phase', 'phenomene', 'philosophe', 'photographe', 'physique', 'piece', 'pied', 'pierre', 'pilier', 'pionnier', 'pire', 'piste', 'place', 'placer', 'plaider', 'plaie', 'plaisir', 'plan', 'planetaire', 'planete', 'plein', 'pleinement', 'plonger', 'plupart', 'pluralisme', 'plus', 'plusieurs', 'plutot', 'poids', 'poignee', 'point', 'pointe', 'pole', 'polemique', 'police', 'politique', 'pollution', 'pologne', 'polonais', 'pompier', 'populaire', 'population', 'port', 'porte', 'portee', 'porter', 'porteur', 'portugais', 'portugal', 'pose', 'poser', 'positif', 'position', 'posseder', 'possibilite', 'possible', 'poste', 'potentiel', 'pourcent', 'pourquoi', 'poursuite', 'poursuivre', 'pourtant', 'pousser', 'pouvoir', 'pragmatisme', 'prague', 'pratique', 'pratiquement', 'pratiquer', 'prealable', 'precarite', 'precaution', 'precedent', 'preceder', 'precieux', 'precisement', 'preciser', 'predecesseur', 'preference', 'preferer', 'prefet', 'prejuge', 'prelevement', 'premier', 'premiere', 'prenant', 'prendra', 'prendre', 'prennent', 'prenon', 'preoccupation', 'preoccuper', 'preparation', 'prepare', 'preparer', 'preparon', 'pres', 'presence', 'present', 'presentation', 'presente', 'presenter', 'preserver', 'preside', 'presidence', 'president', 'presider', 'presque', 'presse', 'prestation', 'prestige', 'prestigieux', 'pret', 'pretendre', 'preter', 'preuve', 'prevaloir', 'prevenir', 'prevention', 'prevoir', 'primaire', 'primordial', 'principal', 'principale', 'principe', 'principer', 'principes', 'printemps', 'priori', 'prioritaire', 'priorite', 'prise', 'prison', 'priver', 'privilege', 'privilegier', 'prix', 'probablement', 'probleme', 'proceder', 'procedure', 'processus', 'prochain', 'prochainement', 'proche', 'proclamer', 'prodigieux', 'producteur', 'production', 'productivite', 'produire', 'produit', 'professeur', 'profession', 'professionnalisation', 'professionnel', 'profit', 'profiter', 'profond', 'profonde', 'profondement', 'profondeur', 'programmation', 'programme', 'progres', 'progresse', 'progresser', 'progressif', 'progression', 'progressivement', 'projet', 'proliferation', 'prolongement', 'prolonger', 'promesse', 'prometteur', 'promotion', 'promouvoir', 'prononcer', 'propos', 'propose', 'proposer', 'proposition', 'propre', 'proprietaire', 'propriete', 'prospere', 'prosperite', 'protection', 'protege', 'proteger', 'protocole', 'prouve', 'prouver', 'province', 'proviseur', 'provoquer', 'proximite', 'prudence', 'psychologique', 'public', 'puis', 'puise', 'puiser', 'puisque', 'puissance', 'puissant', 'puissante', 'puisser', 'qualification', 'qualifie', 'qualifier', 'qualite', 'quand', 'quant', 'quantite', 'quarante', 'quart', 'quartier', 'quatre', 'quatrieme', 'quebec', 'quel', 'quell', 'quelle', 'quelque', 'querelle', 'question', 'quete', 'quinquennat', 'quinze', 'quitter', 'quoi', 'quotidien', 'quotidienne', 'racine', 'radio', 'raison', 'raisonnable', 'ralentir', 'ramener', 'rang', 'rapide', 'rapidement', 'rapides', 'rappeler', 'rapport', 'rapporter', 'rapprochement', 'rapprocher', 'rare', 'rarement', 'rassembl', 'rassemble', 'rassemblement', 'rassembler', 'rassurer', 'ratifier', 'rayonnement', 'reaction', 'reaffirmation', 'reaffirmer', 'reagir', 'realisation', 'realiser', 'realite', 'recemment', 'recent', 'reception', 'recette', 'recevoir', 'recherche', 'rechercher', 'reciproque', 'reclamer', 'recommandation', 'recompense', 'recompenser', 'reconciliation', 'reconcilier', 'reconnaissance', 'reconnaissant', 'reconnaitre', 'reconquerir', 'reconstituer', 'reconstruction', 'recourir', 'recours', 'recrutement', 'recruter', 'recteur', 'recueillir', 'recul', 'reculer', 'redaction', 'redevenir', 'rediger', 'redire', 'redonner', 'redoutable', 'redressement', 'redresser', 'reduction', 'reduire', 'reel', 'reelle', 'reellement', 'reference', 'referendum', 'reflechir', 'reflet', 'reflexe', 'reflexion', 'reform', 'reforme', 'reformer', 'refuge', 'refugie', 'refus', 'refuse', 'refuser', 'regard', 'regarde', 'regarder', 'regime', 'regiment', 'region', 'regional', 'regle', 'reglement', 'reglementation', 'regler', 'regrette', 'regretter', 'regrouper', 'regulier', 'regulierement', 'rejeter', 'rejoindre', 'rejoui', 'rejouir', 'rejouis', 'relache', 'relais', 'relance', 'relancer', 'relatif', 'relation', 'relever', 'relier', 'religieux', 'religion', 'remarquable', 'remarquer', 'remede', 'remedier', 'remercie', 'remerciement', 'remercier', 'remettre', 'remise', 'rempart', 'remplacer', 'remplir', 'remuneration', 'renaissance', 'renaitre', 'rencontre', 'rencontrer', 'rendez', 'rendre', 'renforcement', 'renforcer', 'renoncer', 'renouer', 'renouveau', 'renouveler', 'renouvellement', 'renovation', 'renover', 'renvoyer', 'repandre', 'reparation', 'repartir', 'repartition', 'repere', 'repete', 'repeter', 'repli', 'repondre', 'reponse', 'reporter', 'repose', 'reposer', 'reprendre', 'representant', 'representatif', 'representation', 'represente', 'representer', 'reprise', 'republicain', 'republique', 'reseau', 'reserve', 'reserver', 'resigner', 'resistance', 'resolument', 'resolution', 'resoudre', 'respect', 'respecte', 'respecter', 'respectif', 'respectueu', 'respectueux', 'responsabiliser', 'responsabilite', 'responsable', 'ressembler', 'ressentir', 'resserrer', 'ressource', 'restauration', 'restaurer', 'reste', 'restent', 'rester', 'restriction', 'restructuration', 'resultat', 'resulter', 'retablir', 'retablissement', 'retard', 'retarder', 'retenir', 'retirer', 'retour', 'retraite', 'retrouve', 'retrouver', 'reunion', 'reunir', 'reussir', 'reussite', 'revanche', 'reve', 'reveler', 'revenir', 'revenu', 'rever', 'revetir', 'revient', 'revision', 'revoir', 'revolution', 'revolutionnaire', 'riche', 'richesse', 'rien', 'rigidite', 'rigoureux', 'rigueur', 'rio', 'risque', 'risquer', 'riverain', 'rmi', 'roi', 'role', 'rome', 'rompre', 'rouge', 'roumain', 'roumanie', 'route', 'routier', 'royaume', 'rue', 'rupture', 'rural', 'russe', 'russie', 'rythme', 'sachez', 'sachon', 'sacrer', 'sacrifice', 'sacrifier', 'sagesse', 'sai', 'saint', 'saintete', 'saintetienne', 'saintpetersbourg', 'saisir', 'salaire', 'salarie', 'salarier', 'salle', 'salue', 'saluer', 'salut', 'sanction', 'sanctionner', 'sang', 'sanitaire', 'sans', 'sante', 'satisfaction', 'sauvegarde', 'sauvegarder', 'sauver', 'savant', 'savez', 'savoir', 'sceau', 'sceller', 'scene', 'schema', 'science', 'scientifique', 'scolaire', 'secheresse', 'second', 'secours', 'secret', 'secretaire', 'secretariat', 'secteur', 'seculaire', 'securite', 'sein', 'selon', 'semaine', 'semblable', 'semble', 'sembler', 'senat', 'senateur', 'sens', 'sensibilite', 'sensible', 'sentiment', 'sentir', 'separe', 'separer', 'sept', 'septembre', 'serbe', 'serenite', 'serie', 'serieux', 'serre', 'service', 'servir', 'session', 'seul', 'seulement', 'si', 'sida', 'siecle', 'siege', 'sien', 'sienne', 'signal', 'signature', 'signe', 'signer', 'significatif', 'signification', 'signifier', 'silence', 'simple', 'simplement', 'simplification', 'simplifier', 'simultanement', 'sincere', 'singapour', 'singularite', 'singulier', 'sinon', 'site', 'situation', 'situer', 'six', 'sncf', 'social', 'socialiste', 'societe', 'socle', 'soi', 'soigner', 'soin', 'soir', 'soixante', 'sol', 'soldat', 'solennel', 'solennellement', 'solidaire', 'solidarite', 'solide', 'solidite', 'solitude', 'solliciter', 'solution', 'sombre', 'somme', 'sommet', 'songer', 'sophistiquer', 'sort', 'sorte', 'sortir', 'souci', 'soucieux', 'souffle', 'souffrance', 'souffrir', 'souhait', 'souhaitable', 'souhaite', 'souhaitent', 'souhaiter', 'soulever', 'souligne', 'souligner', 'soumettre', 'souplesse', 'source', 'sourcer', 'sourire', 'sous', 'souscrire', 'sousestimer', 'soutenir', 'soutien', 'souvenir', 'souvent', 'souverain', 'souverainete', 'sovietique', 'spatial', 'special', 'specialement', 'specialiser', 'specialiste', 'specificite', 'specifique', 'spectacle', 'spirituel', 'spontanement', 'sport', 'sportif', 'stabilisation', 'stabilite', 'stable', 'stade', 'statut', 'stimuler', 'strasbourg', 'strategie', 'strategique', 'strict', 'structure', 'structurel', 'structurer', 'subir', 'substance', 'substituer', 'succeder', 'succes', 'successif', 'sud', 'sudafricain', 'sudest', 'suede', 'suedois', 'suffire', 'suffisamment', 'suffisant', 'suffit', 'suffrage', 'suisse', 'suite', 'suivre', 'sujet', 'superbe', 'superieur', 'supplementaire', 'supporter', 'suppose', 'supprimer', 'supreme', 'surcroit', 'surgir', 'surmonter', 'surtout', 'survie', 'susceptible', 'suscite', 'susciter', 'symbole', 'symbolique', 'sympathie', 'synergie', 'synonyme', 'synthese', 'syrie', 'systematique', 'systematiquement', 'systeme', 'table', 'tache', 'talent', 'tandis', 'tant', 'tard', 'tarder', 'taux', 'tcheque', 'technique', 'technologie', 'technologique', 'tel', 'telecommunications', 'television', 'tellement', 'temoignage', 'temoigne', 'temoigner', 'temoin', 'temps', 'tenacite', 'tendance', 'tendre', 'tenir', 'tension', 'tentation', 'tenter', 'terme', 'terminant', 'terminer', 'terrain', 'terre', 'terrible', 'territoire', 'territorial', 'terrorisme', 'terroriste', 'tete', 'texte', 'tgv', 'theatre', 'theme', 'tient', 'tiers', 'tire', 'tirer', 'tisser', 'tissu', 'titre', 'tolerance', 'tolerer', 'tomber', 'tort', 'tot', 'total', 'totalement', 'touche', 'touchent', 'toucher', 'toujours', 'tour', 'tourisme', 'touristique', 'tournant', 'tourne', 'tourner', 'tout', 'toutefois', 'trace', 'tracer', 'tradition', 'traditionnel', 'traduction', 'traduire', 'trafic', 'tragedie', 'tragique', 'train', 'traite', 'traitement', 'traiter', 'trancher', 'transatlantique', 'transfert', 'transformation', 'transforme', 'transformer', 'transmettre', 'transmission', 'transparence', 'transport', 'traumatisme', 'travail', 'travaille', 'travailler', 'travailleur', 'travers', 'traverse', 'traverser', 'trente', 'tres', 'tresor', 'tribune', 'triompher', 'trois', 'troisieme', 'tromper', 'trop', 'trouble', 'troupe', 'trouve', 'trouver', 'tunisie', 'tunisien', 'turbulence', 'turquie', 'type', 'ueo', 'ukraine', 'ultime', 'unesco', 'uni', 'unifier', 'uniforme', 'uniformisation', 'union', 'unique', 'uniquement', 'unir', 'unis', 'unissent', 'unit', 'unite', 'univers', 'universalite', 'universel', 'universelle', 'universitaire', 'universite', 'urbain', 'urbanisme', 'urgence', 'urgent', 'uruguay', 'usage', 'usager', 'usine', 'utile', 'utilisation', 'utiliser', 'vache', 'vain', 'vaincre', 'valeur', 'vallee', 'valoir', 'valoriser', 'varier', 'vaste', 'veille', 'veiller', 'venir', 'venise', 'vent', 'venu', 'veritable', 'veritablement', 'verite', 'verra', 'verre', 'vers', 'verser', 'vertu', 'veux', 'vicepresident', 'victime', 'victoire', 'vie', 'vieillissement', 'viennent', 'vient', 'vietnam', 'vietnamien', 'vieux', 'vif', 'vigilance', 'vigilant', 'vigoureux', 'vigueur', 'village', 'ville', 'vingt', 'vingtcinq', 'violence', 'visage', 'visavis', 'viser', 'vision', 'visionnaire', 'visite', 'visiter', 'visiteur', 'vital', 'vitalite', 'vite', 'vitesse', 'vivant', 'vivent', 'vivr', 'vivre', 'vocation', 'voeu', 'voeux', 'voici', 'voie', 'voila', 'voir', 'voire', 'vois', 'voisin', 'voisinage', 'voiture', 'voix', 'volet', 'volontaire', 'volonte', 'vote', 'voter', 'vouloir', 'voute', 'voyage', 'voyez', 'vrai', 'vraie', 'vraiment', 'vue', 'vulnerable', 'washington', 'xix', 'xxi', 'york', 'yougoslavie', 'zone']"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_tfifd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-bf07debe2b42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_tfifd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_svd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_tfifd' is not defined"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as utils\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "# print(torch.get_default_dtype())\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# train_data_tensor = torch.tensor(X_train_tfifd.toarray())\n",
    "train_data_tensor = torch.tensor(X_train)\n",
    "train_target_tensor = torch.tensor(np.asarray(y_train)) # transform to torch tensors\n",
    "\n",
    "# test_data_tensor = torch.tensor(X_test_tfifd.toarray())\n",
    "test_data_tensor = torch.tensor(X_test)\n",
    "test_target_tensor = torch.tensor(np.asarray(y_test)) # transform to torch tensors\n",
    "\n",
    "train_dataset = utils.TensorDataset(train_data_tensor,train_target_tensor) # create your datset\n",
    "test_dataset = utils.TensorDataset(test_data_tensor,test_target_tensor) # create your datset\n",
    "\n",
    "batch_size = 16\n",
    "# Set the training loader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# Set the testing loader\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights1 = torch.randn(mot_max, 5, requires_grad=True)\n",
    "weights2 = torch.randn(5, 5, requires_grad=True)\n",
    "weights3 = torch.randn(5, 2, requires_grad=True)\n",
    "\n",
    "b1 = torch.randn((1, 5), requires_grad=True) # bias for hidden layer\n",
    "b2 = torch.randn((1, 5), requires_grad=True) # bias for output layer\n",
    "b3 = torch.randn((1, 2), requires_grad=True) # bias for output layer\n",
    "\n",
    "# b1 = torch.randn(500,)\n",
    "# b2 = torch.randn((1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_activation(z):\n",
    "    return 1 / (1 + torch.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy on test set 0.6727336062004703\n"
     ]
    }
   ],
   "source": [
    "def test(weights1, weights2,weights3,b1, b2, b3, test_loader):\n",
    "    test_size = len(test_loader.dataset)\n",
    "    correct = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        #print(batch_idx, data.shape, target.shape)\n",
    "#         data = data.view((-1, 28*28))\n",
    "        #print(batch_idx, data.shape, target.shape)\n",
    "        data = data.float()\n",
    "        target = target.to(dtype=torch.long)        \n",
    "        z1 = torch.matmul(data, weights1) + b1\n",
    "        a1 = sigmoid_activation(z1)\n",
    "        \n",
    "        z2 = torch.matmul(a1, weights2) + b2\n",
    "        a2 = sigmoid_activation(z2)\n",
    "\n",
    "        z3 = torch.matmul(a2, weights3) + b3\n",
    "        \n",
    "        outputs = sigmoid_activation(z3)\n",
    "        \n",
    "        softmax = F.softmax(outputs, dim=1)\n",
    "        pred = softmax.argmax(dim=1, keepdim=True)\n",
    "        n_correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "        correct += n_correct\n",
    "\n",
    "    acc = correct / test_size\n",
    "    print(\" Accuracy on test set\", acc)\n",
    "    return\n",
    "\n",
    "test(weights1, weights2,weights3,b1, b2, b3, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss shape: 0.6601667404174805 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.6287295222282412 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.6079935431480408 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.5940302610397339 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.6015344858169556 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.5424875617027283 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.6087452769279485 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.5370907783508301 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.52741175889968877 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.55050367116928166 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.54726982116699227 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.62719506025314335 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.45647254586219794 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.45022335648536685 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44358417391777045 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.39425584673881535 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38807770609855653 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.57114273309707645 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.47758233547210693 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.52469825744628914 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.47133609652519226 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.47064113616943366 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.51766395568847666 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.36304044723510746 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.41246283054351807 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.51558685302734385 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.51527678966522225 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.62244111299514775 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.51400566101074226 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.40796682238578796 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.46038624644279483 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.46033078432083135 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.45875859260559085 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.51432567834854133 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.51181536912918096 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.40104174613952637 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.62072843313217164 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50966042280197147 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.39807990193367004 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.39879700541496277 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.39824232459068327 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.45346677303314216 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.45428395271301276 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.34031319618225136 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50990498065948496 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.45281079411506653 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.45094826817512515 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.39433556795120247 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.45161810517311096 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.51005804538726815 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.45117053389549255 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.39359059929847725 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50692236423492435 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50778841972351074 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.45067772269248965 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50703001022338874 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.33277910947799683 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50759553909301766 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50834256410598753 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.33274585008621216 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50639581680297856 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38954707980155945 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44847971200942993 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.56523489952087446 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50597232580184947 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44775888323783875 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38930648565292364 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44781899452209474 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38915368914604187 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38781765103340156 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.56418007612228396 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50565379858016975 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38747090101242065 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44720339775085453 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44592049717903137 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44559133052825934 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44545784592628486 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38671386241912845 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44573539495468147 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44551312923431396 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50500088930138534 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.32673427462577823 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50432431697845464 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50450736284255984 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38621085882186896 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38584992289543153 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38564163446426394 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38544452190399177 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44434636831283576 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.3856603205204014 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.3254718780517578 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38515168428421025 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44479084014892585 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.32507976889610294 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44502833485603336 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44473952054977417 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.62459325790405273 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.32466077804565436 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38392475247383124 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44394385814666754 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38381129503250124 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44336491823196415 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44410073757171636 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38413751125335693 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38383290171623236 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.32353064417839055 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50360083580017094 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38363304734230046 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44353500008583075 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.56360703706741337 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.56324321031570433 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.62416142225265514 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44331458210945136 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38315883278846745 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.56435483694076547 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.56486213207244877 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44332981109619146 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.32292211055755615 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.56383872032165533 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38243305683135986 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.56339091062545786 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50369161367416385 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.56426846981048584 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.32207289338111885 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50333744287490845 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38224488496780396 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44283610582351685 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38244724273681646 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44261196255683915 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.32197389006614685 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38239088654518136 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50345295667648323 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.32163977622985846 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.32112067937850954 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38202667236328125 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50275105237960824 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50328224897384643 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.56365895271301277 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.62414550781251085 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44260796904563904 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44210970401763916 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50312525033950814 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50320774316787724 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.32059741020202637 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38107264041900635 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44221085309982374 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38147246837615967 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.56397050619125376 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38124975562095645 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.3814055919647217 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38150110840797424 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50330078601837165 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.32025980949401855 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38123217225074777 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44217014312744144 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.56355047225952156 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38100376725196844 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38123178482055664 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38113406300544746 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44195657968521123 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44168055057525635 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.32006129622459416 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44197592139244083 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50270336866378787 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44176554679870605 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44159710407257086 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.68593388795852666 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50311243534088135 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38065651059150696 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.56366741657257087 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50299370288848885 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.56363052129745485 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38069415092468266 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50252896547317565 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.3801651597023019 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.68558114767074584 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50288116931915284 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.3804400861263275 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44147428870201116 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.56375783681869513 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38058316707611084 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44171035289764404 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50240182876586917 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44117632508277893 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.62489449977874764 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38038036227226267 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.31880471110343933 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50241827964782713 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44117891788482666 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.56350851058959967 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44118499755859375 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44140344858169556 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50254046916961677 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38011530041694644 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44118165969848633 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.31866905093193054 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44116473197937015 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.62515699863433844 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.62462282180786136 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44123828411102295 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44058594107627873 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.56377840042114263 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.38010746240615845 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.31846630573272705 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.68640744686126716 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44115632772445683 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44091668725013733 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44080090522766113 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.56369459629058846 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44103211164474496 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.37962019443511963 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.37954485416412354 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.56377518177032474 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.62502259016036997 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44101640582084656 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.62492716312408457 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50215214490890577 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44093161821365356 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44087573885917664 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44087529182434084 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44106495380401614 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.37937012314796455 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.56345099210739147 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.56356734037399295 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.31779909133911133 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.37933081388473515 Accuracy on test set 0.8679787511974223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss shape: 0.37924355268478394 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50254130363464366 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44079557061195374 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44063013792037964 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44073352217674255 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44066977500915533 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50232410430908246 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44047290086746216 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44040736556053164 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44076195359230047 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50233191251754766 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.56357479095458985 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50204330682754526 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.37921270728111267 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44063729047775275 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44060686230659485 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.62530702352523854 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50189191102981574 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50231164693832447 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50209182500839235 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.37907651066780094 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.31742033362388613 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.37905707955360413 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.37904843688011175 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.31750342249870335 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50197541713714656 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50204497575759896 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44019395112991333 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50192970037460333 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50173163414001463 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.31730881333351135 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.37881463766098025 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.68681269884109546 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44013452529907227 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.37896487116813666 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.37880924344062805 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50197821855545044 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.31722250580787663 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.37875220179557895 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50192046165466314 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44029983878135685 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.37859916687011724 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44041496515274055 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.56330424547195436 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50184649229049683 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.31710228323936464 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.56364977359771736 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50198781490325934 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44028016924858093 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.56352639198303223 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.37860816717147827 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44011294841766365 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.31694450974464417 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50204616785049446 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.56356739997863777 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44045057892799387 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50185936689376836 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.50197881460189824 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.31694650650024414 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.44014552235603337 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.37833091616630554 Accuracy on test set 0.8679787511974223\n",
      "Loss shape: 0.6126736998558044"
     ]
    }
   ],
   "source": [
    "it = 0\n",
    "for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "    # Be sure to start the loop with zeros grad\n",
    "    if weights1.grad is not None:\n",
    "        weights1.grad.zero_()\n",
    "    \n",
    "    if weights2.grad is not None:\n",
    "        weights2.grad.zero_()\n",
    "        \n",
    "    if weights3.grad is not None:\n",
    "        weights3.grad.zero_()\n",
    "    \n",
    "    if b1.grad is not None:\n",
    "        b1.grad.zero_()\n",
    "        \n",
    "    if b2.grad is not None:\n",
    "        b2.grad.zero_()\n",
    "        \n",
    "    if b3.grad is not None:\n",
    "        b3.grad.zero_()\n",
    "        \n",
    "        \n",
    "    #print(\"batch_idx: {}, data.shape: {}, target.shape: {}\".format(batch_idx, data.shape, targets.shape))\n",
    "    data = data.float()\n",
    "    targets = targets.to(dtype=torch.long)\n",
    "    z1 = torch.matmul(data, weights1) + b1\n",
    "    a1 = sigmoid_activation(z1)\n",
    "        \n",
    "    z2 = torch.matmul(a1, weights2) + b2\n",
    "    a2 = sigmoid_activation(z2)\n",
    "\n",
    "    z3 = torch.matmul(a2, weights3) + b3\n",
    "        \n",
    "    outputs = sigmoid_activation(z3)\n",
    "    log_softmax = F.log_softmax(outputs, dim=1)\n",
    "    #print(\"Log softmax: {}\".format(log_softmax.shape))\n",
    "\n",
    "    #print((-log_softmax[0][targets[0]] + -log_softmax[1][targets[1]] )  / 2 )\n",
    "    #print(-log_softmax[0][targets[0]], targets[0])\n",
    "    \n",
    "    loss = F.nll_loss(log_softmax, targets)\n",
    "    print(\"\\rLoss shape: {}\".format(loss), end=\"\")\n",
    "    \n",
    "    # Compute the gradients for each variables\n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        weights3 -= 0.1*weights3.grad\n",
    "        weights2 -= 0.1*weights2.grad\n",
    "        weights1 -= 0.1*weights1.grad\n",
    "        b3 -= 0.1*b3.grad\n",
    "        b2 -= 0.1*b2.grad\n",
    "        b1 -= 0.1*b1.grad\n",
    "\n",
    "\n",
    "    it += 1\n",
    "    if it % 10 == 0:\n",
    "        test(weights1, weights2,weights3,b1, b2, b3, test_loader)\n",
    "        \n",
    "#     if it > 50000:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1], dtype=torch.int32)\n",
      "tensor([[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]])\n"
     ]
    }
   ],
   "source": [
    "batch_idx, (data, target) = next(enumerate(test_loader))\n",
    "data = data.float()\n",
    "# for i in data[0]:\n",
    "#     print(i)\n",
    "print(target)\n",
    "z1 = torch.matmul(data, weights1) + b1\n",
    "a1 = sigmoid_activation(z1)       \n",
    "z2 = torch.matmul(a1, weights2) + b2\n",
    "a2 = sigmoid_activation(z2)\n",
    "z3 = torch.matmul(a2, weights3) + b3      \n",
    "outputs = sigmoid_activation(z3)\n",
    "softmax = F.softmax(outputs, dim=1)\n",
    "pred = softmax.argmax(dim=1, keepdim=True)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
